{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IagZMs0_qjdL"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "Welcome to the Lab5. In this lab, you will build a convolutional neural network step by step. In this notebook, you will implement all the functions required to build a convolutional neural network.\n",
    "\n",
    "After finishing this lab, you will have a deeper understanding of the process of training a convolutional neural network, which mainly consists of two parts: convolution layer and pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGFR00CQvoaH"
   },
   "source": [
    "# 2. Import Packages\n",
    "\n",
    "1. To build a convolutional neural network, we start by importing the Dense layer, Activation layer, and Loss function that you implemented in Lab4. Ensure the following three files are located in the same directory as this notebook, and follow the instructions to complete the setup:\n",
    "    - Dense.py : Copy the **Dense class** you had implemented in Lab4 to it.\n",
    "    - Activation.py : Copy the **Activation class** you had implemented in Lab4 to it.\n",
    "    - Loss.py : Copy **compute_BCE_loss** function you had implemented in Lab4 to it.\n",
    "\n",
    "2. Helper function\n",
    "    - Predict.py : This file contains a helper function for model prediction and evaluation. **No modifications are required** for this file.\n",
    "\n",
    "⚠️ **WARNING** ⚠️:\n",
    "*   Please do not import any other packages in this lab.\n",
    "*   np.random.seed(seed) is used to keep all the random function calls consistent. It will help us grade your work. Please don't change the seed.\n",
    "\n",
    "❗ **Important** ❗: Please do not change the code outside this code bracket.\n",
    "```\n",
    "### START CODE HERE ### (≈ n lines)\n",
    "...\n",
    "### END CODE HERE ###\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf8X57wOQo1w"
   },
   "source": [
    "Mount Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YcLLrIEc-4h6"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fmTH9UkeqdYf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###### import your HW4 code######\n",
    "from Dense import Dense\n",
    "from Activation import Activation\n",
    "from Loss import compute_BCE_loss\n",
    "from Predict import predict\n",
    "##################################\n",
    "\n",
    "output = {}\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xme1U0TCQo1x"
   },
   "source": [
    "# 3. Basic part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMe4BNRPRQvF"
   },
   "source": [
    "## 3.1 Convolution layer\n",
    "\n",
    "Convolution layer enables us to capture the important features of input images.\n",
    "\n",
    "In this section, we will focus on convolution layer. The implemented function will be gradually incorporated into this class, so you should use self.function() whenever you need to call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzSk8alpQo1x"
   },
   "source": [
    "### 3.1.1 Initialize the Convolution layer\n",
    "\n",
    "First, we initialize the Convolution layer and set up the weights and biases of the convolutional filters using Glorot uniform initialization.\n",
    "\n",
    "- It will take following parameters to initialize the convolution layer:\n",
    "\n",
    "    *   filter_size: Defines the dimensions of the filter, which will be of shape (filter_size x filter_size).\n",
    "    \n",
    "    *   input_channel: Specifies the size of the input channel.\n",
    "    \n",
    "    *   output_channel: Specifies the size of the output channel.\n",
    "    \n",
    "    *   pad: The amount of padding applied around each image along the vertical and horizontal dimensions.\n",
    "    \n",
    "    *   stride: The number of steps the filter moves during each operation.\n",
    "    \n",
    "**Note: No implementation is required for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rClniXjDQo1x"
   },
   "outputs": [],
   "source": [
    "class Conv():\n",
    "    def __init__(self, filter_size=2, input_channel=3, output_channel=8, pad=1, stride=1, seed=1):\n",
    "\n",
    "        self.filter_size= filter_size\n",
    "        self.input_channel=input_channel\n",
    "        self.output_channel=output_channel\n",
    "        self.seed = seed\n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "\n",
    "        self.parameters = {'W':None, 'b': None}\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        self.parameters -- python dictionary containing your parameters:\n",
    "                           W -- weight matrix of shape (filter_size, filter_size, input channel size, output channel size)\n",
    "                           b -- bias vector of shape (1, 1, 1, output channel size)\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        sd = np.sqrt(6.0 / (self.input_channel + self.output_channel))\n",
    "        W = np.random.uniform(-sd, sd, (self.filter_size,self.filter_size,self.input_channel,self.output_channel))\n",
    "        b = np.zeros((1, 1, 1, self.output_channel))\n",
    "\n",
    "        assert(W.shape == (self.filter_size,self.filter_size,self.input_channel,self.output_channel))\n",
    "        assert(b.shape == (1,1,1,self.output_channel))\n",
    "\n",
    "        self.parameters['W'] = W\n",
    "        self.parameters['b'] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WI-1JUPjQo1y"
   },
   "source": [
    "### 3.1.2 Zero-Padding\n",
    "\n",
    "Implement the zero_pad() function to pad the input X with the given parameter on vertical and horizontal dimensions with zero.\n",
    "\n",
    "- It allows you to use a convolution layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks since otherwise the height/width would shrink as you go to deeper layers.\n",
    "\n",
    "- It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.\n",
    "\n",
    "**Note:** This function is **not included** as a method in the Conv class, so you can call zero_pad() directly whenever you need to use it.\n",
    "\n",
    "**Hint:** You can use function [np.pad](https://numpy.org/doc/2.0/reference/generated/numpy.pad.html) to add the specified amount of zero-padding around image on both the vertical and horizontal dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ADlgENHVRQvG"
   },
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad all images in the dataset X with zeros. The padding should be applied to both the height and width of each image.\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C), where m represent the number of examples.\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant')\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ukYzbawQo1y"
   },
   "source": [
    "#### **Test and Evaluate** the **zero_pad** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "hRpzM6qxQo1y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[0,2,:,0] = [-0.3224172   1.13376944 -0.17242821]\n",
      "x_pad[0,2,:,0] = [ 0.          0.          1.62434536 -0.52817175  0.86540763  0.\n",
      "  0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[0,2,:,0] =\", x[0,2,:,0])\n",
    "print (\"x_pad[0,2,:,0] =\", x_pad[0,2,:,0])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])\n",
    "\n",
    "np.random.seed(seed)\n",
    "x = np.random.randn(4, 2, 2, 2)\n",
    "x_pad = zero_pad(x, 1)\n",
    "output[\"zero_padding\"] = x_pad[0,1,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG3MiZBlQo1y"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>x.shape: </td>\n",
    "    <td>(4, 3, 3, 2)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>x_pad.shape: </td>\n",
    "    <td>(4, 7, 7, 2)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>x[0,2,:,0]: </td>\n",
    "    <td>[-0.3224172   1.13376944 -0.17242821]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>x_pad[0,2,:,0]: </td>\n",
    "    <td>[ 0. 0. 1.62434536 -0.52817175 0.86540763 0. 0.]\n",
    "</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDvCjY4LQo1y"
   },
   "source": [
    "### 3.1.3 Convolution Single Step\n",
    "\n",
    "In this section, you will implement the **conv_single_step** function which will apply a filter to a single region f * f of the input data.\n",
    "\n",
    "<span style=\"font-size: 25px;\">Key Concepts</span>\n",
    "\n",
    "* Convolution is performed using a sliding window of size f * f, where f is the filter size.\n",
    "  \n",
    "* This function applies a convolution filter of dimensions (f, f, n_c_prev) on an input slice of shape (f, f, n_c_prev), resulting in a single scalar value.\n",
    "\n",
    "* In section 3.1.4, we would slide the filter along (H,W) coordinate to get a 2D feature map for the filter\n",
    "\n",
    "<span style=\"font-size: 25px;\">Steps in the conv_single_step implementation</span>\n",
    "\n",
    "1. **Step 1:** Do element-wise product to a_slice_prev and W to get shape (f, f, n_c_prev).\n",
    "   \n",
    "2. **Step 2:** Sum all values to get a single scalar, reducing the (f, f, n_C_prev) matrix into a single scalar.\n",
    "   \n",
    "3. **Step 3:** Add the bias b to the scalar result. Cast b to a float() so that Z results in a scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vQzL2D3yQo1y"
   },
   "outputs": [],
   "source": [
    "def conv_single_step(self, a_slice_prev, W, b):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        a_slice_prev -- slice of previous activation layer output with shape (filter_size, filter_size, n_C_prev)\n",
    "        W -- Weight parameters contained in a window - matrix of shape (filter_size, filter_size, n_C_prev)\n",
    "        b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "\n",
    "        Returns:\n",
    "        Z -- a scalar value, Zult of convolving the sliding window (W, b) on a slice x of the input data\n",
    "        \"\"\"\n",
    "\n",
    "        ### START CODE HERE ### (≈ 3 lines)\n",
    "        # Step 1: Element-wise product to a_slice_prev and W\n",
    "        Z = a_slice_prev * W\n",
    "        # Step 2: Sum all values to get a single scalar\n",
    "        Z = np.sum(Z)\n",
    "        # Step 3: Add the bias\n",
    "        Z = Z + b.item()\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return Z\n",
    "\n",
    "Conv.conv_single_step = conv_single_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YKNLaiJQo1z"
   },
   "source": [
    "#### **Test and Evaluate** the **conv_single_step** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "02WmPxJKJbJa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "conv = Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
    "Z = conv.conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)\n",
    "\n",
    "np.random.seed(seed)\n",
    "a_slice_prev = np.random.randn(3, 3, 3)\n",
    "W = np.random.randn(3, 3, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "conv = Conv()\n",
    "Z = conv.conv_single_step(a_slice_prev, W, b)\n",
    "output[\"conv_single_step\"] = Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVHY5VIFVLiC"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>Z: </td>\n",
    "    <td>-6.999089450680221</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfVBJ8ScQo1z"
   },
   "source": [
    "### 3.1.4 Forward Pass\n",
    "\n",
    "In this section, you will take multiple filters and convolve them through the input. Each filter produces a 2D matrix output, and stacking these matrices creates a 3D output volume.\n",
    "\n",
    "The **conv_single_step** function is essential for this process. During the **Forward pass**, we call **conv_single_step** repeatedly on different slices of the input along (H,W) coordinate to build the entire 2D output matrix for each filter. This involves the following steps:\n",
    "\n",
    "**Step 1: Calculate the Output Dimension**:\n",
    "   \n",
    "- The final output of the convolution operation is a 3D volume with dimensions (n_H, n_W, n_C):\n",
    "\n",
    "  - Height: n_H $= \\left\\lfloor \\frac{H_{prev} - filter\\_size + 2 \\times \\text{pad}}{\\text{stride}} \\right\\rfloor + 1$\n",
    "\n",
    "  - Width: n_W $= \\left\\lfloor \\frac{W_{prev} - filter\\_size + 2 \\times \\text{pad}}{\\text{stride}} \\right\\rfloor + 1$\n",
    "\n",
    "  - Depth: n_C, which is the number of filters\n",
    "\n",
    "**Step 2: Padding**:\n",
    "\n",
    "- Pad the input based on the padding value to ensure that we correctly calculate the output volumn for each position.\n",
    "\n",
    "**Step 3: Loop Through Training Examples**:\n",
    "\n",
    "The input data has dimensions (m, n_H_prev, n_W_prev, n_C_prev), where m represents the number of input data.\n",
    "\n",
    "For each training example, follow these steps to compute the output volumn:\n",
    "\n",
    "- **Step 3-1: Extracting slices**:\n",
    "\n",
    "  - For each position (h, w, c) in the output matrix, we define a slice of the input within the sliding window where each slice has dimensions (f, f, n_C_prev).\n",
    "\n",
    "  - In each operation, we slide the window with a defined stride along the (H, W) coordinates to extract different slice.\n",
    "\n",
    "- **Step 3-2: Applying Filters**:\n",
    "\n",
    "  - For each slice of shape (f, f, n_C_prev), we apply a filter also of shape (f, f, n_C_prev) using **conv_single_step**.\n",
    "\n",
    "  - This element-wise multiplication and summation over the entire slice and filter result in a single scalar output, reducing (f, f, n_C_prev) to (1, 1, 1).\n",
    "\n",
    "  - By iterating over all positions (h, w) across the height and width of the input, **conv_single_step** computes the result at each position, building up a 2D matrix of size (n_H, n_W) for each filter.\n",
    "\n",
    "  - By iterating over all filters (which correspond to the output channels), we build up a 3D output volume of shape (n_H, n_W, n_C), where n_C is the number of filters used in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "H0SJ42G2Qo1z"
   },
   "outputs": [],
   "source": [
    "def forward(self, A_prev):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = self.parameters[\"W\"].shape\n",
    "\n",
    "\n",
    "    # Step 1: Output Dimension Calculation\n",
    "    pad = self.pad\n",
    "    stride = self.stride\n",
    "    n_H = int(np.floor((n_H_prev-f+2*pad) / stride)) + 1\n",
    "    n_W = int(np.floor((n_W_prev-f+2*pad) / stride)) + 1\n",
    "\n",
    "    # Initialize the output volume Z with zeros\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    # Step 2: Padding\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "\n",
    "    # Step 3: Loop Through Training Examples\n",
    "    for h in range(n_H):                           # loop over vertical axis of the output volume\n",
    "        for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
    "            # Step 3-1: Extracting slices\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            horiz_start = w * stride\n",
    "            horiz_end = horiz_start + f\n",
    "\n",
    "            # Extract the volume for all examples\n",
    "            a_slice = A_prev_pad[:, vert_start:vert_end, horiz_start:horiz_end, :]  # Shape: (m, f, f, n_C_prev)\n",
    "\n",
    "            # Step 3-2: Applying Filters\n",
    "            # W: (f, f, n_C_prev, n_C), a_slice: (m, f, f, n_C_prev)\n",
    "            # Result: Z[:, h, w, c] where c ranges from 0 to n_C\n",
    "            Z[:, h, w, :] = np.tensordot(a_slice, self.parameters[\"W\"], axes=([1, 2, 3], [0, 1, 2])) + self.parameters[\"b\"]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "\n",
    "    # Save information in \"cache\" for the backward pass\n",
    "    self.cache = A_prev\n",
    "\n",
    "    return Z\n",
    "\n",
    "Conv.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDu808HWQo1z"
   },
   "source": [
    "#### **Test and Evaluate** the **forward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6Ags0LKKRQvH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's shape = (10, 4, 4, 8)\n",
      "Z's mean = 0.003190416988183084\n",
      "Z[3,2,1] = [ 1.32947002  2.12083471  0.37853495 -3.53602735  1.38816885 -1.01503137\n",
      " -1.01667531  0.86993377]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "conv=Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
    "Z = conv.forward(A_prev)\n",
    "\n",
    "print(\"Z's shape =\", Z.shape)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(10,3,3,2)\n",
    "conv=Conv(filter_size=3, input_channel=2, output_channel=16, pad=1, stride=1)\n",
    "Z = conv.forward(A_prev)\n",
    "\n",
    "output[\"conv_forward_1\"] = Z.shape\n",
    "output[\"conv_forward_2\"] = np.mean(Z)\n",
    "output[\"conv_forward_3\"] = Z[3,2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qiBeJbhVTlU"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>Z's shape: </td>\n",
    "    <td>(10, 4, 4, 8)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Z's mean: </td>\n",
    "    <td>0.0031904169881830785</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Z[3,2,1]: </td>\n",
    "    <td>[ 1.32947002  2.12083471  0.37853495 -3.53602735  1.38816885 -1.01503137\n",
    " -1.01667531  0.86993377]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45MLJaL6Qo1z"
   },
   "source": [
    "### 3.1.5 Backward Pass\n",
    "\n",
    "In this section, we calculate the gradients of the cost function with respect to the input, weights, and biases of the convolutional layer. This allows us to update these parameters during training. The backward pass involves the following gradients:\n",
    "\n",
    "- **dA_prev**: Gradient of the cost with respect to the input of the conv layer, with dimensions (m, n_H_prev, n_W_prev, n_C_prev).\n",
    "  \n",
    "- **dW**: Gradient of the cost with respect to the weights of the conv layer, with dimensions (f, f, n_C_prev, n_C).\n",
    "  \n",
    "- **db**: Gradient of the cost with respect to the biases of the conv layer, with dimensions (1, 1, 1, n_C).\n",
    "\n",
    "<span style=\"font-size: 25px;\">Backward Pass Steps</span>\n",
    "\n",
    "Given the gradient of the cost with respect to the output of the convolutional layer, dZ, which has dimensions (m, n_H, n_W, n_C), the backward pass proceeds as follows:\n",
    "\n",
    "**Step 1: Initialize Gradients**:\n",
    "\n",
    "- Create dA_prev, dW, and db with the correct shapes\n",
    "\n",
    "**Step 2: Padding**:\n",
    "\n",
    "- Pad A_prev and dA_prev based on the padding value to ensure that we correctly calculate the gradients for each position\n",
    "\n",
    "**Step 3: Loop Through Training Examples**:\n",
    "\n",
    "For each training example, follow these steps to compute and update the gradients:\n",
    "\n",
    "- **Step 3-1: Extracting slices**:\n",
    "\n",
    "  - This step is the same as what you have implemented in **Forward pass**. The slice is used to calculate the gradient of filter's weight.\n",
    "\n",
    "- **Step 3-2: Update the Gradients**:\n",
    "\n",
    "    $$\n",
    "  dA^{l-1} = \\frac{\\partial L}{\\partial Z^l} \\times \\frac{\\partial Z^l}{\\partial A^{l-1}} = \\frac{\\partial L}{\\partial A^{l-1}}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  dW^l = \\frac{1}{m} \\times \\frac{\\partial L}{\\partial Z^l} \\times \\frac{\\partial Z^l}{\\partial W^l} = \\frac{\\partial L}{\\partial W^l}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  db^l = \\frac{1}{m} \\times \\frac{\\partial L}{\\partial Z^l} \\times \\frac{\\partial Z^l}{\\partial b^l} = \\frac{\\partial L}{\\partial b^l}\n",
    "  $$\n",
    "\n",
    "  **Hint:**\n",
    "  - $ \\frac{\\partial L}{\\partial Z^l} $ corresponds to $ dZ $\n",
    "  - m is the batch size\n",
    "  - $ Z_{h,w,c}^l = A_{f \\times f}^{l-1} * W_{c}^l + b_{c}^l $ , where f is the kernel size\n",
    "  \n",
    "  Iterating over the height, width, and channels of the output to compute the full set of gradients.\n",
    "\n",
    "**Step 4: Remove Padding**:\n",
    "- After calculating the gradients for all slices, remove the padding from dA_prev_pad to obtain dA_prev with shape (m, n_H_prev, n_W_prev, n_C_prev).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TPrUOk-cQo1z"
   },
   "outputs": [],
   "source": [
    "def backward(self, dZ):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a convolution layer\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
    "                numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    A_prev = self.cache\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = self.parameters[\"W\"].shape\n",
    "\n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "\n",
    "    # Step 1: Initialize Gradients\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # Step 2: Padding\n",
    "    A_prev_pad = zero_pad(A_prev, self.pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, self.pad)\n",
    "\n",
    "    # Step 3: Loop Through Training Examples\n",
    "    for h in range(n_H):\n",
    "        for w in range(n_W):\n",
    "             # Step 3-1: Extracting slices\n",
    "            vert_start = h * self.stride\n",
    "            vert_end = vert_start + f\n",
    "            horiz_start = w * self.stride\n",
    "            horiz_end = horiz_start + f\n",
    "            a_slice = A_prev_pad[:, vert_start:vert_end, horiz_start:horiz_end, :]  # Shape: (m, f, f, n_C_prev)\n",
    "\n",
    "            # Step 3-2: Update the Gradients\n",
    "            # Compute dW[:, :, :, c] using tensordot between dZ and slice\n",
    "            dW += np.tensordot(a_slice, dZ[:, h, w, :], axes=([0], [0])) / m\n",
    "\n",
    "            # Update dA_prev_pad[:, vert_start:vert_end, horiz_start:horiz_end, :] for all channels\n",
    "            for c in range(n_C):\n",
    "                dA_prev_pad[:, vert_start:vert_end, horiz_start:horiz_end, :] += dZ[:, h, w, c][:, None, None, None] * self.parameters[\"W\"][:, :, :, c]\n",
    "\n",
    "        # Step 4: Remove Padding\n",
    "        dA_prev = dA_prev_pad[:, self.pad:-self.pad, self.pad:-self.pad, :]\n",
    "    \n",
    "    db = np.sum(dZ, axis=(0, 1, 2), keepdims=True) / m\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "\n",
    "    self.dW = dW\n",
    "    self.db = db\n",
    "\n",
    "    return dA_prev\n",
    "\n",
    "Conv.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otcu5-e9Qo10"
   },
   "source": [
    "#### **Test and Evaluate** the **backward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "r4bSxlOLQo10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev's shape = (10, 4, 4, 3)\n",
      "dA_prev's mean = 0.00655067636329092\n",
      "dA_prev[3,2,1] = [-0.33079703 -1.64413855  0.34342549]\n",
      "dW[0,0,0,:] = [ 0.628421    0.27688478 -0.15725264  0.60455304  0.16843747  1.00921225\n",
      "  0.55441834  0.1224805 ]\n",
      "db[0,0,0,:] = [ 2.83837596  1.10463954  0.17494534  0.94603986 -1.05306856 -0.45070565\n",
      "  0.15993941  1.32191626]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "dZ = np.random.randn(10,4,4,8)\n",
    "conv = Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
    "conv.cache = np.random.randn(10,4,4,3)\n",
    "dA_prev = conv.backward(dZ)\n",
    "\n",
    "print(\"dA_prev's shape =\", dA_prev.shape)\n",
    "print(\"dA_prev's mean =\", np.mean(dA_prev))\n",
    "print(\"dA_prev[3,2,1] =\", dA_prev[3,2,1])\n",
    "print(\"dW[0,0,0,:] =\", conv.dW[0,0,0,:])\n",
    "print(\"db[0,0,0,:] =\", conv.db[0,0,0,:])\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "dZ = np.random.randn(10,3,3,16)\n",
    "conv = Conv(filter_size=3, input_channel=2, output_channel=16, pad=1, stride=1)\n",
    "conv.cache = np.random.randn(10,3,3,2)\n",
    "dA_prev = conv.backward(dZ)\n",
    "\n",
    "output[\"conv_backward_1\"] = dA_prev.shape\n",
    "output[\"conv_backward_2\"] = np.mean(dA_prev)\n",
    "output[\"conv_backward_3\"] = dA_prev[3,2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yug_W_MYQo10"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>dA_prev's shape: </td>\n",
    "    <td>(10, 4, 4, 3)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dA_prev's mean: </td>\n",
    "    <td>0.00655067636329092</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Z[3,2,1]: </td>\n",
    "    <td>[-0.33079703 -1.64413855  0.34342549]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dW[0,0,0,:]: </td>\n",
    "    <td>[ 0.628421    0.27688478 -0.15725264  0.60455304  0.16843747  1.00921225, 0.55441834  0.1224805 ]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>db[0,0,0,:]: </td>\n",
    "    <td>[ 2.83837596  1.10463954  0.17494534  0.94603986 -1.05306856 -0.45070565 0.15993941  1.32191626]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbGLz2F_ReRr"
   },
   "source": [
    "### 3.1.6 Update parameters\n",
    "In this section, you will update the parameters of the convolution layer, using gradient descent:\n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$\n",
    "$$b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "jF5XbAziQo10"
   },
   "outputs": [],
   "source": [
    "def update(self, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "\n",
    "    Arguments:\n",
    "    learning rate -- step size\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    self.parameters[\"W\"] = self.parameters[\"W\"] - learning_rate * self.dW\n",
    "    self.parameters[\"b\"] = self.parameters[\"b\"] - learning_rate * self.db\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "Conv.update = update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th-w_C4vQo10"
   },
   "source": [
    "#### **Test and Evaluate** the **update** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QOw8N6q7RgGU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W[0,0,0:2] =  [[-1.76806747  0.99336963 -0.33765555  0.73059859 -1.47724437]\n",
      " [ 1.59544843 -2.28822502  0.49371023 -0.49784308  0.31660293]]\n",
      "b =  [[[[ 0.75439794 -1.25286816 -0.51292982  0.29809284 -0.48851815]]]]\n"
     ]
    }
   ],
   "source": [
    "conv=Conv(filter_size=2, input_channel=3, output_channel=5, pad=2, stride=2)\n",
    "np.random.seed(seed)\n",
    "conv.dW = np.random.randn(2, 2, 3, 5)\n",
    "conv.db = np.random.randn(1, 1, 1, 5)\n",
    "conv.update(1.0)\n",
    "print(\"W[0,0,0:2] = \", conv.parameters[\"W\"][0,0,0:2])\n",
    "print(\"b = \", conv.parameters[\"b\"])\n",
    "\n",
    "conv=Conv(filter_size=3, input_channel=3, output_channel=5, pad=2, stride=2)\n",
    "np.random.seed(seed)\n",
    "conv.dW = np.random.randn(3, 3, 3, 5)\n",
    "conv.db = np.random.randn(1, 1, 1, 5)\n",
    "conv.update(1.0)\n",
    "output[\"conv_update_1\"] = conv.parameters[\"W\"][0,0,0:2]\n",
    "output[\"conv_update_2\"] = conv.parameters[\"b\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WBrdsS9RsTA"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>W[0,0,0:2]: </td>\n",
    "    <td>[[-1.76806747  0.99336963 -0.33765555  0.73059859 -1.47724437][1.59544843 -2.28822502  0.49371023 -0.49784308  0.31660293]]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b: </td>\n",
    "    <td>[[[[ 0.75439794 -1.25286816 -0.51292982  0.29809284 -0.48851815]]]]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goYhkmioRQvI"
   },
   "source": [
    "## 3.2 Maxpooling layer\n",
    "\n",
    "The pooling layer reduces the size (height and width) of the input. It helps reduce computation, as well as makes feature detectors more invariant to their position in the input.\n",
    "\n",
    "In this section, we will focus on Maxpooling layer. The implemented function will be gradually incorporated into this class, so you should use self.function() whenever you need to call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK7eH6aGQo10"
   },
   "source": [
    "### 3.2.1 Initialize the Maxpooling layer\n",
    "\n",
    "First, we initialize the Maxpooling layer.\n",
    "\n",
    "- It will take following parameters to initialize the Maxpooling layer:\n",
    "\n",
    "    *   pool_size: Defines the dimensions of the pooling window, which will be of shape (pool_size x pool_size).\n",
    "    \n",
    "    *   stride: The number of steps the pooling window moves during each operation.\n",
    "\n",
    "- Function **create_mask_from_window** is used in the backward pass to aid in backpropagating gradients through the pooling layer.\n",
    "    \n",
    "**Note: No implementation is required for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "yjg2Lh6qQo11"
   },
   "outputs": [],
   "source": [
    "class MaxPool():\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def create_mask_from_window(self, x):\n",
    "        \"\"\"\n",
    "        Creates a mask from an input x to identify the max entry of x.\n",
    "\n",
    "        Arguments:\n",
    "        x -- Array of shape (filter_size, filter_size)\n",
    "\n",
    "        Returns:\n",
    "        mask -- Array of the same shape as filter, contains a True at the position corresponding to the max entry of x.\n",
    "        \"\"\"\n",
    "\n",
    "        mask = x == np.max(x)\n",
    "\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqoB5MBSQo11"
   },
   "source": [
    "### 3.2.2 Forward pass\n",
    "\n",
    "In this section, you will slide a ( pool_size * pool_size ) window over the input and store the max value of the window in the output.\n",
    "\n",
    "This involves the following steps:\n",
    "\n",
    "**Step 1: Calculate the Output Dimension**\n",
    "   \n",
    "- The output of the maxpooling operation is of shape (n_H, n_W, n_C):\n",
    "\n",
    "  - Height: n_H $= \\left\\lfloor \\frac{H_{prev} - pool\\_size}{\\text{stride}} \\right\\rfloor + 1$\n",
    "\n",
    "  - Width: n_W $= \\left\\lfloor \\frac{W_{prev} - pool\\_size}{\\text{stride}} \\right\\rfloor + 1$\n",
    "\n",
    "  - Depth: n_C_prev, which corresponds to the number of input channels\n",
    "\n",
    "**Step 2: Loop Through Training Examples**\n",
    "\n",
    "For each training example, follow these steps to perform maxpooling operation:\n",
    "    \n",
    "- **Step 2-1: Extracting slices**:\n",
    "\n",
    "  - This step is the same as what you have implemented in **Conv.forward**, but now we extract only one channel at a time to perform the max-pooling operation.\n",
    "\n",
    "- **Step 2-2: Applying Maxpooling**:\n",
    "   \n",
    "  - For each slice of shape (p, p , 1), calculate the maximum value from the slice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WAX5OHXgQo11"
   },
   "outputs": [],
   "source": [
    "def forward(self, A_prev):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the max pooling layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "\n",
    "    # Step 1: Output Dimension Calculation\n",
    "    n_H = int(np.floor((n_H_prev-self.pool_size) / self.stride)) + 1\n",
    "    n_W = int(np.floor((n_W_prev-self.pool_size) / self.stride)) + 1\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    # initialize output matrix A with zeros\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    # Step 2: Loop Through Training Examples\n",
    "    for h in range(n_H):                        # loop on the vertical axis of the output volume\n",
    "        for w in range(n_W):                    # loop on the horizontal axis of the output volume\n",
    "            # Step 2-1: Extracting slices\n",
    "            vert_start = h * self.stride\n",
    "            vert_end = vert_start + self.pool_size\n",
    "            horiz_start = w * self.stride\n",
    "            horiz_end = horiz_start + self.pool_size\n",
    "            a_prev_slice = A_prev[:, vert_start:vert_end, horiz_start:horiz_end, :]  # Shape: (m, pool_size, pool_size, n_C)\n",
    "\n",
    "            # Step 2-2: Applying Maxpooling\n",
    "            A[:, h, w, :] = np.max(a_prev_slice, axis=(1, 2))\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Store the input in \"cache\" for backward pass\n",
    "    self.cache = A_prev\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "\n",
    "    return A\n",
    "\n",
    "MaxPool.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oW4gkFQQo11"
   },
   "source": [
    "#### **Test and Evaluate** the **forward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "BpL0HQvQRQvJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = [[[[1.74481176 0.86540763 1.13376944]]]\n",
      "\n",
      "\n",
      " [[[1.13162939 1.51981682 2.18557541]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "maxpool=MaxPool(pool_size=3, stride=2)\n",
    "A = maxpool.forward(A_prev)\n",
    "print(\"A =\", A)\n",
    "\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "maxpool=MaxPool(pool_size=2, stride=1)\n",
    "A = maxpool.forward(A_prev)\n",
    "output[\"maxpool_forward\"] = A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vcEzFinVYHP"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>A: </td>\n",
    "    <td>[[[[1.74481176 0.86540763 1.13376944]]]\n",
    "\n",
    "\n",
    " [[[1.13162939 1.51981682 2.18557541]]]]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fznc1tR0Qo11"
   },
   "source": [
    "### 3.2.3 Backward Pass\n",
    "\n",
    "In the backward pass, you will distribute the gradient from the output back to the input. The gradient will only pass through the location of the maximum value selected during the forward pass. During this process, the output gradient dA is propagated back to the input by identifying where the maximum value occurred in each pooling window.\n",
    "\n",
    "<span style=\"font-size: 25px;\">Backward Pass Steps</span>\n",
    "\n",
    "Given the gradient of the cost with respect to the output of the pooling layer, dA, which has the same shape as A, the backward pass proceeds as follows:\n",
    "\n",
    "**Step 1: Initialize Gradients**:\n",
    "\n",
    "   - Create dA_prev with the correct shapes\n",
    "\n",
    "**Step 2: Loop Through Training Examples**:\n",
    "\n",
    "   For each training example, follow these steps to pass through the gradients:\n",
    "\n",
    "   - **Step 3-1: Extracting slices**:\n",
    "\n",
    "     - This step is the same as what you have implemented in **Forward pass**.\n",
    "\n",
    "   - **Step 3-2: Pass through the Gradients**:\n",
    "\n",
    "      - call **create_mask_from_window** and apply the mask to the input gradient to backpropagate only the location of  maximum value within the window.\n",
    "      \n",
    "      Iterating over the height, width, and channels of the output to compute the full set of gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "dZbg-lrFQo12"
   },
   "outputs": [],
   "source": [
    "def backward(self, dA):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the max pooling layer\n",
    "\n",
    "    Arguments:\n",
    "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve information from cache\n",
    "    A_prev = self.cache\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "\n",
    "    # Step 1: Initialize Gradients\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))\n",
    "\n",
    "    # Step 2: Loop Through Training Examples\n",
    "    for h in range(n_H):                       # loop on the vertical axis of the output volume\n",
    "        for w in range(n_W):                    # loop on the horizontal axis of the output volume\n",
    "            # Step 2-1: Extracting slices\n",
    "            vert_start = h * self.stride\n",
    "            vert_end = vert_start + self.pool_size\n",
    "            horiz_start = w * self.stride\n",
    "            horiz_end = horiz_start + self.pool_size\n",
    "            a_prev_slice = A_prev[:, vert_start:vert_end, horiz_start:horiz_end, :]  # Shape: (m, pool_size, pool_size, n_C)\n",
    "\n",
    "            # Step 2-2: Pass through the Gradients\n",
    "            mask = (a_prev_slice == np.max(a_prev_slice, axis=(1, 2), keepdims=True))  # Shape: (m, pool_size, pool_size, n_C)\n",
    "            dA_prev[:, vert_start:vert_end, horiz_start:horiz_end, :] += mask * dA[:, h, w, :][:, None, None, :]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Make sure your output shape is correct\n",
    "\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "\n",
    "    return dA_prev\n",
    "\n",
    "MaxPool.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgZ5GQK2Qo12"
   },
   "source": [
    "#### **Test and Evaluate** the **backward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "r023NZUnQo12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev[0] = [[[ 1.62434536  0.          0.        ]\n",
      "  [ 0.         -0.61175641  0.        ]]\n",
      "\n",
      " [[ 0.          0.         -0.52817175]\n",
      "  [ 0.          0.          0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "dA = np.random.randn(2, 1, 1, 3)\n",
    "maxpool = MaxPool(pool_size=2, stride=2)\n",
    "maxpool.cache = np.random.randn(2, 2, 2, 3)\n",
    "dA_prev = maxpool.backward(dA)\n",
    "print(\"dA_prev[0] =\", dA_prev[0])\n",
    "\n",
    "dA = np.random.randn(2, 1, 1, 2)\n",
    "maxpool = MaxPool(pool_size=3, stride=3)\n",
    "maxpool.cache = np.random.randn(2, 3, 3, 2)\n",
    "dA_prev = maxpool.backward(dA)\n",
    "output[\"maxpool_backward\"] = dA_prev[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPg8sITPQo12"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>dA_prev[0]: </td>\n",
    "    <td>[[[ 1.62434536  0.          0.        ][ 0.         -0.61175641  0.        ]]\n",
    "\n",
    " [[ 0.          0.         -0.52817175]\n",
    "  [ 0.          0.          0.        ]]]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn-VBGGURQvJ"
   },
   "source": [
    "## 3.3 Flatten layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJN7EvSuaKGW"
   },
   "source": [
    "To connect the convolution layer and the dense layer, you should flatten the output of the convolution layer or max pooling layer before dense layer.\n",
    "\n",
    "In this section, we will focus on Flatten layer. The implemented function will be gradually incorporated into this class, so you should use self.function() whenever you need to call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "e1K19Y_SQo12"
   },
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Haf0l4nau3y"
   },
   "source": [
    "### 3.3.1 Forward pass\n",
    "\n",
    "The forward pass of the flatten layer converts each example in the input into a single row by flattening along the spatial dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "5aw8ZJ9WQo13"
   },
   "outputs": [],
   "source": [
    "def forward(self, A_prev):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the flatten layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "\n",
    "    Returns:\n",
    "    A -- output of the flatten layer, a 2-dimensional array of shape (m, (n_H_prev * n_W_prev * n_C_prev))\n",
    "    \"\"\"\n",
    "\n",
    "    # Save information in \"cache\" for the backward pass\n",
    "    self.cache = A_prev.shape\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    A = A_prev.reshape((A_prev.shape[0], -1))\n",
    "    ### END CODE HERE ###\n",
    "    return A\n",
    "\n",
    "Flatten.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gj12447QQo13"
   },
   "source": [
    "#### **Test and Evaluate** the **forward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "TF96C0Fyat_4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape = (2, 8)\n",
      "A[0] = [ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
      "  1.74481176 -0.7612069 ]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(2,2,2,2)\n",
    "flatten = Flatten()\n",
    "A = flatten.forward(A_prev)\n",
    "print(\"A.shape =\", A.shape)\n",
    "print(\"A[0] =\", A[0])\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(2,3,3,2)\n",
    "flatten = Flatten()\n",
    "A = flatten.forward(A_prev)\n",
    "output[\"flatten_forward\"] = A[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq3qbOjiVhjj"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>A.shape: </td>\n",
    "    <td>(2, 8)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>A[0]: </td>\n",
    "    <td>[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
    "  1.74481176 -0.7612069 ]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdWPIB6_a8_n"
   },
   "source": [
    "### 3.3.2  Backward pass\n",
    "\n",
    "Here, we only need to reshape the input gradients back to their original dimensions (matching the output shape of the previous layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "iL1MguUlQo13"
   },
   "outputs": [],
   "source": [
    "def backward(self, dA):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the flatten layer\n",
    "\n",
    "    Arguments:\n",
    "    dA -- Input data, a 2-dimensional array\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- An array with its original shape (the output shape of its' previous layer).\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    dA_prev = dA.reshape(self.cache)\n",
    "    ### END CODE HERE ###\n",
    "    return dA_prev\n",
    "\n",
    "Flatten.backward = backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6r3cHzTQo13"
   },
   "source": [
    "#### **Test and Evaluate** the **backward** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "dY8vpJPLauWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.shape = (2, 2, 2, 2)\n",
      "B[0] = [[[ 1.62434536 -0.61175641]\n",
      "  [-0.52817175 -1.07296862]]\n",
      "\n",
      " [[ 0.86540763 -2.3015387 ]\n",
      "  [ 1.74481176 -0.7612069 ]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(2,2,2,2)\n",
    "flatten = Flatten()\n",
    "A = flatten.forward(A_prev)\n",
    "B = flatten.backward(A)\n",
    "print(\"B.shape =\", B.shape)\n",
    "print(\"B[0] =\", B[0])\n",
    "\n",
    "# B and A_prev should be same\n",
    "assert((B==A_prev).all())\n",
    "\n",
    "np.random.seed(seed)\n",
    "A_prev = np.random.randn(4,3,3,3)\n",
    "flatten = Flatten()\n",
    "A = flatten.forward(A_prev)\n",
    "B = flatten.backward(A)\n",
    "output[\"flatten_backward\"] = B[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3khMiPehVjIV"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>B.shape: </td>\n",
    "    <td>(2, 2, 2, 2)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>B[0]: </td>\n",
    "    <td>[[[ 1.62434536 -0.61175641]\n",
    "  [-0.52817175 -1.07296862]]\n",
    "\n",
    " [[ 0.86540763 -2.3015387 ]\n",
    "  [ 1.74481176 -0.7612069 ]]]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYqpQu6Eye7h"
   },
   "source": [
    "## 3.4 Model\n",
    "Alright, now you have all the tools that are needed to build a convolutional neural network. Let's get started! Use the knowledge you learned from Lab4 to finish this part. But the method to build our model is slightly different:\n",
    "\n",
    "1. In this lab, we will call model.add( ) to add a layer into the model. For example:\n",
    "    * model.add(Conv( )): add a convolution layer into the model.\n",
    "    * model.add(Dense( )): add a dense layer into the model.\n",
    "    * model.add(Activation( )): add an activation layer into the model.\n",
    "\n",
    "2. There’s no need to pass loss function parameters when defining the Activation layer.\n",
    "    * You can simply call Activation('relu', None).\n",
    "\n",
    "In this section, we will use all the layers we've defined to build the model. You can refer to page 5 of the Lab 5 slides to see how a CNN stacks each layer together. There remains some functions to complete.\n",
    "\n",
    "- **1. forward**\n",
    "\n",
    "  - For each layer, call its forward function to compute the final output.\n",
    "\n",
    "- **2. backward**\n",
    "\n",
    "  - For the final ($L_{th}$) layer: Since we only perform binary classification in this lab, the last layer will always be a sigmoid activation. Refer to Lab4 for guidance on backpropagating through a sigmoid activation.\n",
    "\n",
    "  - For the remaining layers: Call each layer’s backward function to calculate gradients.\n",
    "\n",
    "- **3. update**\n",
    "\n",
    "  - For the Conv and Dense layers, call the update function to update the parameters.\n",
    "\n",
    "  **Hint:**\n",
    "  - You can use layer.\\_\\_class\\_\\_.\\_\\_name\\_\\_ to obtain the name of each layer.\n",
    "  - Remember to call the method of the layer inside the class, rather than calling it directly. For example, use self.layer.forward() instead of just forward().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7dWrCCkPRQvK"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        A = X\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        for l in range(len(self.layers)):\n",
    "            A = self.layers[l].forward(A)\n",
    "        ### END CODE HERE ###\n",
    "        return A\n",
    "\n",
    "    def backward(self, AL=None, Y=None):\n",
    "        L = len(self.layers)\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        dAL = - (np.divide(Y, AL+1e-5) - np.divide(1-Y, 1-AL+1e-5))\n",
    "        dA_prev = self.layers[-1].backward(dAL)\n",
    "        # Loop from l=L-2 to l=0\n",
    "        for l in reversed(range(L-1)):\n",
    "            dA_prev = self.layers[l].backward(dA_prev)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return dA_prev\n",
    "\n",
    "    def update(self, learning_rate):\n",
    "\n",
    "        # Only convolution layer and dense layer have to update parameters\n",
    "        ### START CODE HERE ###\n",
    "        for l in range(len(self.layers)):\n",
    "        #   print(self.layers[l].__class__.__name__)\n",
    "          if self.layers[l].__class__.__name__ in {\"Conv\", \"Dense\"}:\n",
    "            self.layers[l].update(learning_rate)\n",
    "        ### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36my0zWnlv3K"
   },
   "source": [
    "#### **Test and Evaluate** the **Model** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gN-8NQ_KRQvK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers[0].dW[0,0,0] = [ 0.09033835 -0.02115584 -0.00031401 -0.18961698 -0.02691661 -0.07641501\n",
      " -0.15402248  0.04322364]\n",
      "model.layers[0].db = [[[[-0.04353359 -0.29034244  0.55228045  0.27299323  0.27469552\n",
      "    -0.24907673  0.55674122 -0.05243406]]]]\n",
      "model.layers[4].dW[:8,0] = [-2.14606176 -0.75085187 -1.19750975 -0.8916535  -0.91436404 -0.76753\n",
      " -1.30207298 -0.52670234]\n",
      "model.layers[4].db = [[-0.47493517]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "A = np.random.randn(4,10,10,3)\n",
    "Y = np.expand_dims(np.array([1,0,1,0]),-1)\n",
    "\n",
    "model=Model()\n",
    "model.add(Conv(filter_size=3, input_channel=3, output_channel=8, pad=1, stride=2))\n",
    "model.add(Activation(\"relu\", None))\n",
    "model.add(MaxPool(pool_size=2, stride=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, 1))\n",
    "model.add(Activation(\"sigmoid\", None))\n",
    "\n",
    "\n",
    "AL = model.forward(A)\n",
    "dA_prev = model.backward(AL=AL, Y=Y)\n",
    "model.update(0.01)\n",
    "\n",
    "print(\"model.layers[0].dW[0,0,0] =\", model.layers[0].dW[0,0,0])\n",
    "print(\"model.layers[0].db =\", model.layers[0].db)\n",
    "print(\"model.layers[4].dW[:8,0] =\", model.layers[4].dW[:8, 0])\n",
    "print(\"model.layers[4].db =\", model.layers[4].db)\n",
    "\n",
    "\n",
    "np.random.seed(seed)\n",
    "A = np.random.randn(4,8,8,3)\n",
    "Y = np.expand_dims(np.array([1,1,0,0]),-1)\n",
    "\n",
    "model=Model()\n",
    "model.add(Conv(filter_size=3, input_channel=3, output_channel=16, pad=1, stride=2))\n",
    "model.add(Activation(\"relu\", None))\n",
    "model.add(MaxPool(pool_size=2, stride=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, 1))\n",
    "model.add(Activation(\"sigmoid\", None))\n",
    "\n",
    "\n",
    "AL = model.forward(A)\n",
    "dA_prev = model.backward(AL=AL, Y=Y)\n",
    "model.update(0.001)\n",
    "\n",
    "output[\"model_1\"] = model.layers[0].dW[0,0,0]\n",
    "output[\"model_2\"] = model.layers[0].db\n",
    "output[\"model_3\"] = model.layers[4].dW[:8, 0]\n",
    "output[\"model_4\"] = model.layers[4].db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGTtpnWcVvce"
   },
   "source": [
    "Expected output:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>model.layers[0].dW[0,0,0]: </td>\n",
    "    <td>[ 0.09033835 -0.02115584 -0.00031401 -0.18961698 -0.02691661 -0.07641501\n",
    " -0.15402248  0.04322364]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>model.layers[0].db: </td>\n",
    "    <td>[[[[-0.04353359 -0.29034244  0.55228045  0.27299323  0.27469552\n",
    "    -0.24907673  0.55674122 -0.05243406]]]]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>model.layers[4].dW[:8,0]: </td>\n",
    "    <td>[-2.14606176 -0.75085187 -1.19750975 -0.8916535  -0.91436404 -0.76753\n",
    " -1.30207298 -0.52670234]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>model.layers[4].db: </td>\n",
    "    <td>[[-0.47493517]]</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkJeG7PHQo14"
   },
   "source": [
    "# 4. Advanced part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EC0qy26RQvN"
   },
   "source": [
    "Congratulations on implementing all the functions by yourself. You have done an incredible job! 👏\n",
    "\n",
    "Now you have all the tools you need to get started with classification. In this section, you will build a binary classifier using the functions you had previously written. You will create a model that can determine whether a chest X-ray image is normal or not. There will be 600 training images and 600 testing images, and the size of all images are 32 * 32 * 1.\n",
    "\n",
    "\n",
    "- Implement a binary classifier and tune the hyperparameter.\n",
    "\n",
    "- You will receive 10% if your prediction accuracy exceeds 0.65 on the testing data and 20% if it exceeds 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2X2fb7aoJTg"
   },
   "source": [
    "## 4.1 Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "LTZ4JKCoQo14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(600, 32, 32, 1), y=(600, 1)\n",
      "Test: X=(600, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Use np.load to load the data from npz file\n",
    "### START CODE HERE ###\n",
    "data = np.load(\"data.npz\")\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "### END CODE HERE ###\n",
    "\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(X_train[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(y_train[i])\n",
    "# show the figure\n",
    "plt.show()\n",
    "\n",
    "# check the shape of training data and testing data\n",
    "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "print('Test: X=%s' % (X_test.shape, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "iwhza4gUboQ6"
   },
   "outputs": [],
   "source": [
    "#You can split training and validation set here using train_test_split (Optional)\n",
    "### START CODE HERE ###\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdK9_gnZAjYD"
   },
   "source": [
    "## 4.2 mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "LVTeqK9TqMwP"
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape !!!!!!!!!!!(number of examples ,input size)!!!!!!!!!!!\n",
    "    Y -- true \"label\" vector, of shape (number of examples, 1)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]  # number of training examples\n",
    "    mini_batches = []\n",
    "\n",
    "    # GRADED CODE: Binary classification\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :]\n",
    "    shuffled_Y = Y[permutation, :]\n",
    "\n",
    "    inc = mini_batch_size\n",
    "\n",
    "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
    "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * inc:(k + 1) * inc, :]\n",
    "        mini_batch_Y = shuffled_Y[k * inc:(k + 1) * inc, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * inc:m, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * inc:m, :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "\n",
    "    return mini_batches\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FIrnqYMFGRq"
   },
   "source": [
    "## 4.3 Start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMqcaNynQo15"
   },
   "source": [
    "- Refer to page 5 of the Lab5 slides as a guide to build your model.\n",
    "- Use ReLU as the activation function in the convolutional block instead of Sigmoid.\n",
    "- Note that the final convolutional block doesn’t necessarily require a max-pooling layer.\n",
    "\n",
    "**Note:** If training takes too long, consider reducing the output dimension before the dense layer or increasing the batch size. For example, a dense layer with 10,000 neurons might take around 3 hours to train, while reducing this to 128 neurons or fewer could complete training in about 30 minutes. This is just an approximation—feel free to design the model according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, rate=0.5):\n",
    "        \"\"\"\n",
    "        Initializes the Dropout layer.\n",
    "\n",
    "        Arguments:\n",
    "        rate -- probability of dropping a neuron output, a float between 0 and 1\n",
    "        \"\"\"\n",
    "        self.rate = rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, A, training=True):\n",
    "        \"\"\"\n",
    "        Implements the forward pass for the dropout layer.\n",
    "\n",
    "        Arguments:\n",
    "        A -- Input data, numpy array of any shape\n",
    "        training -- boolean, whether it is training phase or testing phase\n",
    "\n",
    "        Returns:\n",
    "        A_dropout -- output after applying dropout\n",
    "        \"\"\"\n",
    "        if training:\n",
    "            self.mask = np.random.rand(*A.shape) > self.rate\n",
    "            A_dropout = A * self.mask / (1 - self.rate)\n",
    "        else:\n",
    "            A_dropout = A\n",
    "\n",
    "        return A_dropout\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Implements the backward pass for the dropout layer.\n",
    "\n",
    "        Arguments:\n",
    "        dA -- gradient of the cost with respect to the output of this layer\n",
    "\n",
    "        Returns:\n",
    "        dA_prev -- gradient of the cost with respect to the input of this layer\n",
    "        \"\"\"\n",
    "        dA_prev = dA * self.mask / (1 - self.rate)\n",
    "        return dA_prev\n",
    "\n",
    "# Adding Dropout layer to the model\n",
    "Dropout.forward = forward\n",
    "Dropout.backward = backward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "1CBktduDyKd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Cost after iteration 1: 0.663488\n",
      "epoch:  2\n",
      "Cost after iteration 2: 0.644216\n",
      "epoch:  3\n",
      "Cost after iteration 3: 0.596520\n",
      "epoch:  4\n",
      "Cost after iteration 4: 0.588596\n",
      "epoch:  5\n",
      "Cost after iteration 5: 0.635811\n",
      "epoch:  6\n",
      "Cost after iteration 6: 0.418947\n",
      "epoch:  7\n",
      "Cost after iteration 7: 0.468025\n",
      "epoch:  8\n",
      "Cost after iteration 8: 0.446344\n",
      "epoch:  9\n",
      "Cost after iteration 9: 0.362447\n",
      "epoch:  10\n",
      "Cost after iteration 10: 0.261187\n",
      "epoch:  11\n",
      "Cost after iteration 11: 0.302629\n",
      "epoch:  12\n",
      "Cost after iteration 12: 0.392425\n",
      "epoch:  13\n",
      "Cost after iteration 13: 0.262566\n",
      "epoch:  14\n",
      "Cost after iteration 14: 0.171095\n",
      "epoch:  15\n",
      "Cost after iteration 15: 0.218199\n",
      "epoch:  16\n",
      "Cost after iteration 16: 0.229874\n",
      "epoch:  17\n",
      "Cost after iteration 17: 0.607495\n",
      "epoch:  18\n",
      "Cost after iteration 18: 0.100503\n",
      "epoch:  19\n",
      "Cost after iteration 19: 0.239288\n",
      "epoch:  20\n",
      "Cost after iteration 20: 0.165277\n",
      "epoch:  21\n",
      "Cost after iteration 21: 0.195329\n",
      "epoch:  22\n",
      "Cost after iteration 22: 0.108035\n",
      "epoch:  23\n",
      "Cost after iteration 23: 0.148534\n",
      "epoch:  24\n",
      "Cost after iteration 24: 0.253434\n",
      "epoch:  25\n",
      "Cost after iteration 25: 0.159158\n",
      "epoch:  26\n",
      "Cost after iteration 26: 0.119659\n",
      "epoch:  27\n",
      "Cost after iteration 27: 0.087101\n",
      "epoch:  28\n",
      "Cost after iteration 28: 0.105927\n",
      "epoch:  29\n",
      "Cost after iteration 29: 0.238470\n",
      "epoch:  30\n",
      "Cost after iteration 30: 0.064142\n",
      "epoch:  31\n",
      "Cost after iteration 31: 0.099218\n",
      "epoch:  32\n",
      "Cost after iteration 32: 0.131892\n",
      "epoch:  33\n",
      "Cost after iteration 33: 0.083051\n",
      "epoch:  34\n",
      "Cost after iteration 34: 0.101093\n",
      "epoch:  35\n",
      "Cost after iteration 35: 0.099864\n",
      "epoch:  36\n",
      "Cost after iteration 36: 0.145817\n",
      "epoch:  37\n",
      "Cost after iteration 37: 0.111677\n",
      "epoch:  38\n",
      "Cost after iteration 38: 0.073300\n",
      "epoch:  39\n",
      "Cost after iteration 39: 0.168553\n",
      "epoch:  40\n",
      "Cost after iteration 40: 0.119262\n",
      "epoch:  41\n",
      "Cost after iteration 41: 0.084501\n",
      "epoch:  42\n",
      "Cost after iteration 42: 0.057727\n",
      "epoch:  43\n",
      "Cost after iteration 43: 0.110074\n",
      "epoch:  44\n",
      "Cost after iteration 44: 0.070628\n",
      "epoch:  45\n",
      "Cost after iteration 45: 0.089592\n",
      "epoch:  46\n",
      "Cost after iteration 46: 0.059896\n",
      "epoch:  47\n",
      "Cost after iteration 47: 0.127246\n",
      "epoch:  48\n",
      "Cost after iteration 48: 0.179220\n",
      "epoch:  49\n",
      "Cost after iteration 49: 0.102481\n",
      "epoch:  50\n",
      "Cost after iteration 50: 0.100358\n",
      "epoch:  51\n",
      "Cost after iteration 51: 0.082979\n",
      "epoch:  52\n",
      "Cost after iteration 52: 0.047524\n",
      "epoch:  53\n",
      "Cost after iteration 53: 0.040718\n",
      "epoch:  54\n",
      "Cost after iteration 54: 0.099110\n",
      "epoch:  55\n",
      "Cost after iteration 55: 0.090354\n",
      "epoch:  56\n",
      "Cost after iteration 56: 0.039895\n",
      "epoch:  57\n",
      "Cost after iteration 57: 0.113463\n",
      "epoch:  58\n",
      "Cost after iteration 58: 0.054483\n",
      "epoch:  59\n",
      "Cost after iteration 59: 0.029616\n",
      "epoch:  60\n",
      "Cost after iteration 60: 0.137787\n",
      "epoch:  61\n",
      "Cost after iteration 61: 0.115086\n",
      "epoch:  62\n",
      "Cost after iteration 62: 0.049197\n",
      "epoch:  63\n",
      "Cost after iteration 63: 0.019999\n",
      "epoch:  64\n",
      "Cost after iteration 64: 0.026667\n",
      "epoch:  65\n",
      "Cost after iteration 65: 0.039686\n",
      "epoch:  66\n",
      "Cost after iteration 66: 0.026934\n",
      "epoch:  67\n",
      "Cost after iteration 67: 0.064347\n",
      "epoch:  68\n",
      "Cost after iteration 68: 0.139346\n",
      "epoch:  69\n",
      "Cost after iteration 69: 0.072114\n",
      "epoch:  70\n",
      "Cost after iteration 70: 0.033607\n",
      "epoch:  71\n",
      "Cost after iteration 71: 0.037339\n",
      "epoch:  72\n",
      "Cost after iteration 72: 0.111446\n",
      "epoch:  73\n",
      "Cost after iteration 73: 0.024374\n",
      "epoch:  74\n",
      "Cost after iteration 74: 0.023475\n",
      "epoch:  75\n",
      "Cost after iteration 75: 0.064160\n",
      "epoch:  76\n",
      "Cost after iteration 76: 0.052859\n",
      "epoch:  77\n",
      "Cost after iteration 77: 0.026282\n",
      "epoch:  78\n",
      "Cost after iteration 78: 0.056895\n",
      "epoch:  79\n",
      "Cost after iteration 79: 0.054804\n",
      "epoch:  80\n",
      "Cost after iteration 80: 0.028274\n",
      "epoch:  81\n",
      "Cost after iteration 81: 0.059205\n",
      "epoch:  82\n",
      "Cost after iteration 82: 0.032072\n",
      "epoch:  83\n",
      "Cost after iteration 83: 0.062137\n",
      "epoch:  84\n",
      "Cost after iteration 84: 0.042599\n",
      "epoch:  85\n",
      "Cost after iteration 85: 0.019018\n",
      "epoch:  86\n",
      "Cost after iteration 86: 0.013490\n",
      "epoch:  87\n",
      "Cost after iteration 87: 0.049741\n",
      "epoch:  88\n",
      "Cost after iteration 88: 0.062338\n",
      "epoch:  89\n",
      "Cost after iteration 89: 0.019486\n",
      "epoch:  90\n",
      "Cost after iteration 90: 0.054806\n",
      "epoch:  91\n",
      "Cost after iteration 91: 0.093809\n",
      "epoch:  92\n",
      "Cost after iteration 92: 0.029981\n",
      "epoch:  93\n",
      "Cost after iteration 93: 0.032856\n",
      "epoch:  94\n",
      "Cost after iteration 94: 0.021266\n",
      "epoch:  95\n",
      "Cost after iteration 95: 0.046505\n",
      "epoch:  96\n",
      "Cost after iteration 96: 0.042612\n",
      "epoch:  97\n",
      "Cost after iteration 97: 0.013268\n",
      "epoch:  98\n",
      "Cost after iteration 98: 0.046605\n",
      "epoch:  99\n",
      "Cost after iteration 99: 0.028354\n",
      "epoch:  100\n",
      "Cost after iteration 100: 0.025348\n",
      "epoch:  101\n",
      "Cost after iteration 101: 0.077099\n",
      "epoch:  102\n",
      "Cost after iteration 102: 0.042149\n",
      "epoch:  103\n",
      "Cost after iteration 103: 0.069197\n",
      "epoch:  104\n",
      "Cost after iteration 104: 0.036695\n",
      "epoch:  105\n",
      "Cost after iteration 105: 0.042832\n",
      "epoch:  106\n",
      "Cost after iteration 106: 0.018472\n",
      "epoch:  107\n",
      "Cost after iteration 107: 0.010545\n",
      "epoch:  108\n",
      "Cost after iteration 108: 0.028994\n",
      "epoch:  109\n",
      "Cost after iteration 109: 0.011160\n",
      "epoch:  110\n",
      "Cost after iteration 110: 0.038168\n",
      "epoch:  111\n",
      "Cost after iteration 111: 0.007536\n",
      "epoch:  112\n",
      "Cost after iteration 112: 0.029175\n",
      "epoch:  113\n",
      "Cost after iteration 113: 0.020907\n",
      "epoch:  114\n",
      "Cost after iteration 114: 0.035104\n",
      "epoch:  115\n",
      "Cost after iteration 115: 0.039644\n",
      "epoch:  116\n",
      "Cost after iteration 116: 0.014495\n",
      "epoch:  117\n",
      "Cost after iteration 117: 0.024701\n",
      "epoch:  118\n",
      "Cost after iteration 118: 0.047924\n",
      "epoch:  119\n",
      "Cost after iteration 119: 0.027699\n",
      "epoch:  120\n",
      "Cost after iteration 120: 0.013046\n",
      "epoch:  121\n",
      "Cost after iteration 121: 0.046675\n",
      "epoch:  122\n",
      "Cost after iteration 122: 0.005677\n",
      "epoch:  123\n",
      "Cost after iteration 123: 0.037562\n",
      "epoch:  124\n",
      "Cost after iteration 124: 0.029677\n",
      "epoch:  125\n",
      "Cost after iteration 125: 0.059059\n",
      "epoch:  126\n",
      "Cost after iteration 126: 0.013998\n",
      "epoch:  127\n",
      "Cost after iteration 127: 0.023083\n",
      "epoch:  128\n",
      "Cost after iteration 128: 0.003225\n",
      "epoch:  129\n",
      "Cost after iteration 129: 0.011524\n",
      "epoch:  130\n",
      "Cost after iteration 130: 0.006730\n",
      "epoch:  131\n",
      "Cost after iteration 131: 0.015368\n",
      "epoch:  132\n",
      "Cost after iteration 132: 0.030386\n",
      "epoch:  133\n",
      "Cost after iteration 133: 0.045008\n",
      "epoch:  134\n",
      "Cost after iteration 134: 0.008780\n",
      "epoch:  135\n",
      "Cost after iteration 135: 0.004304\n",
      "epoch:  136\n",
      "Cost after iteration 136: 0.017418\n",
      "epoch:  137\n",
      "Cost after iteration 137: 0.034334\n",
      "epoch:  138\n",
      "Cost after iteration 138: 0.009977\n",
      "epoch:  139\n",
      "Cost after iteration 139: 0.025405\n",
      "epoch:  140\n",
      "Cost after iteration 140: 0.025172\n",
      "epoch:  141\n",
      "Cost after iteration 141: 0.008429\n",
      "epoch:  142\n",
      "Cost after iteration 142: 0.013703\n",
      "epoch:  143\n",
      "Cost after iteration 143: 0.005201\n",
      "epoch:  144\n",
      "Cost after iteration 144: 0.029792\n",
      "epoch:  145\n",
      "Cost after iteration 145: 0.015507\n",
      "epoch:  146\n",
      "Cost after iteration 146: 0.016973\n",
      "epoch:  147\n",
      "Cost after iteration 147: 0.005502\n",
      "epoch:  148\n",
      "Cost after iteration 148: 0.003265\n",
      "epoch:  149\n",
      "Cost after iteration 149: 0.021712\n",
      "epoch:  150\n",
      "Cost after iteration 150: 0.042360\n",
      "epoch:  151\n",
      "Cost after iteration 151: 0.005247\n",
      "epoch:  152\n",
      "Cost after iteration 152: 0.012346\n",
      "epoch:  153\n",
      "Cost after iteration 153: 0.022975\n",
      "epoch:  154\n",
      "Cost after iteration 154: 0.029003\n",
      "epoch:  155\n",
      "Cost after iteration 155: 0.015040\n",
      "epoch:  156\n",
      "Cost after iteration 156: 0.028523\n",
      "epoch:  157\n",
      "Cost after iteration 157: 0.019769\n",
      "epoch:  158\n",
      "Cost after iteration 158: 0.028365\n",
      "epoch:  159\n",
      "Cost after iteration 159: 0.031587\n",
      "epoch:  160\n",
      "Cost after iteration 160: 0.017163\n",
      "epoch:  161\n",
      "Cost after iteration 161: 0.014910\n",
      "epoch:  162\n",
      "Cost after iteration 162: 0.026240\n",
      "epoch:  163\n",
      "Cost after iteration 163: 0.024849\n",
      "epoch:  164\n",
      "Cost after iteration 164: 0.036743\n",
      "epoch:  165\n",
      "Cost after iteration 165: 0.012141\n",
      "epoch:  166\n",
      "Cost after iteration 166: 0.010911\n",
      "epoch:  167\n",
      "Cost after iteration 167: 0.009824\n",
      "epoch:  168\n",
      "Cost after iteration 168: 0.005858\n",
      "epoch:  169\n",
      "Cost after iteration 169: 0.014044\n",
      "epoch:  170\n",
      "Cost after iteration 170: 0.011181\n",
      "epoch:  171\n",
      "Cost after iteration 171: 0.033503\n",
      "epoch:  172\n",
      "Cost after iteration 172: 0.019692\n",
      "epoch:  173\n",
      "Cost after iteration 173: 0.006593\n",
      "epoch:  174\n",
      "Cost after iteration 174: 0.003994\n",
      "epoch:  175\n",
      "Cost after iteration 175: 0.013114\n",
      "epoch:  176\n",
      "Cost after iteration 176: 0.008072\n",
      "epoch:  177\n",
      "Cost after iteration 177: 0.008965\n",
      "epoch:  178\n",
      "Cost after iteration 178: 0.014154\n",
      "epoch:  179\n",
      "Cost after iteration 179: 0.013455\n",
      "epoch:  180\n",
      "Cost after iteration 180: 0.012154\n",
      "epoch:  181\n",
      "Cost after iteration 181: 0.021875\n",
      "epoch:  182\n",
      "Cost after iteration 182: 0.012761\n",
      "epoch:  183\n",
      "Cost after iteration 183: 0.028437\n",
      "epoch:  184\n",
      "Cost after iteration 184: 0.026436\n",
      "epoch:  185\n",
      "Cost after iteration 185: 0.016251\n",
      "epoch:  186\n",
      "Cost after iteration 186: 0.014198\n",
      "epoch:  187\n",
      "Cost after iteration 187: 0.019469\n",
      "epoch:  188\n",
      "Cost after iteration 188: 0.019154\n",
      "epoch:  189\n",
      "Cost after iteration 189: 0.007915\n",
      "epoch:  190\n",
      "Cost after iteration 190: 0.019294\n",
      "epoch:  191\n",
      "Cost after iteration 191: 0.008748\n",
      "epoch:  192\n",
      "Cost after iteration 192: 0.005150\n",
      "epoch:  193\n",
      "Cost after iteration 193: 0.005943\n",
      "epoch:  194\n",
      "Cost after iteration 194: 0.017540\n",
      "epoch:  195\n",
      "Cost after iteration 195: 0.009776\n",
      "epoch:  196\n",
      "Cost after iteration 196: 0.027074\n",
      "epoch:  197\n",
      "Cost after iteration 197: 0.007801\n",
      "epoch:  198\n",
      "Cost after iteration 198: 0.003102\n",
      "epoch:  199\n",
      "Cost after iteration 199: 0.009908\n",
      "epoch:  200\n",
      "Cost after iteration 200: 0.012384\n",
      "epoch:  201\n",
      "Cost after iteration 201: 0.008201\n",
      "epoch:  202\n",
      "Cost after iteration 202: 0.025855\n",
      "epoch:  203\n",
      "Cost after iteration 203: 0.007247\n",
      "epoch:  204\n",
      "Cost after iteration 204: 0.018117\n",
      "epoch:  205\n",
      "Cost after iteration 205: 0.018666\n",
      "epoch:  206\n",
      "Cost after iteration 206: 0.010897\n",
      "epoch:  207\n",
      "Cost after iteration 207: 0.018118\n",
      "epoch:  208\n",
      "Cost after iteration 208: 0.008396\n",
      "epoch:  209\n",
      "Cost after iteration 209: 0.014743\n",
      "epoch:  210\n",
      "Cost after iteration 210: 0.011428\n",
      "epoch:  211\n",
      "Cost after iteration 211: 0.017216\n",
      "epoch:  212\n",
      "Cost after iteration 212: 0.009378\n",
      "epoch:  213\n",
      "Cost after iteration 213: 0.023069\n",
      "epoch:  214\n",
      "Cost after iteration 214: 0.008268\n",
      "epoch:  215\n",
      "Cost after iteration 215: 0.029233\n",
      "epoch:  216\n",
      "Cost after iteration 216: 0.006077\n",
      "epoch:  217\n",
      "Cost after iteration 217: 0.020797\n",
      "epoch:  218\n",
      "Cost after iteration 218: 0.031827\n",
      "epoch:  219\n",
      "Cost after iteration 219: 0.020355\n",
      "epoch:  220\n",
      "Cost after iteration 220: 0.007451\n",
      "epoch:  221\n",
      "Cost after iteration 221: 0.018158\n",
      "epoch:  222\n",
      "Cost after iteration 222: 0.006587\n",
      "epoch:  223\n",
      "Cost after iteration 223: 0.012213\n",
      "epoch:  224\n",
      "Cost after iteration 224: 0.012409\n",
      "epoch:  225\n",
      "Cost after iteration 225: 0.030853\n",
      "epoch:  226\n",
      "Cost after iteration 226: 0.005008\n",
      "epoch:  227\n",
      "Cost after iteration 227: 0.027750\n",
      "epoch:  228\n",
      "Cost after iteration 228: 0.017376\n",
      "epoch:  229\n",
      "Cost after iteration 229: 0.012099\n",
      "epoch:  230\n",
      "Cost after iteration 230: 0.010363\n",
      "epoch:  231\n",
      "Cost after iteration 231: 0.007515\n",
      "epoch:  232\n",
      "Cost after iteration 232: 0.008221\n",
      "epoch:  233\n",
      "Cost after iteration 233: 0.027087\n",
      "epoch:  234\n",
      "Cost after iteration 234: 0.022021\n",
      "epoch:  235\n",
      "Cost after iteration 235: 0.001774\n",
      "epoch:  236\n",
      "Cost after iteration 236: 0.010321\n",
      "epoch:  237\n",
      "Cost after iteration 237: 0.036095\n",
      "epoch:  238\n",
      "Cost after iteration 238: 0.022381\n",
      "epoch:  239\n",
      "Cost after iteration 239: 0.009341\n",
      "epoch:  240\n",
      "Cost after iteration 240: 0.014748\n",
      "epoch:  241\n",
      "Cost after iteration 241: 0.015695\n",
      "epoch:  242\n",
      "Cost after iteration 242: 0.014784\n",
      "epoch:  243\n",
      "Cost after iteration 243: 0.003792\n",
      "epoch:  244\n",
      "Cost after iteration 244: 0.006947\n",
      "epoch:  245\n",
      "Cost after iteration 245: 0.018389\n",
      "epoch:  246\n",
      "Cost after iteration 246: 0.017589\n",
      "epoch:  247\n",
      "Cost after iteration 247: 0.008942\n",
      "epoch:  248\n",
      "Cost after iteration 248: 0.012179\n",
      "epoch:  249\n",
      "Cost after iteration 249: 0.015852\n",
      "epoch:  250\n",
      "Cost after iteration 250: 0.017971\n",
      "epoch:  251\n",
      "Cost after iteration 251: 0.009719\n",
      "epoch:  252\n",
      "Cost after iteration 252: 0.021936\n",
      "epoch:  253\n",
      "Cost after iteration 253: 0.018318\n",
      "epoch:  254\n",
      "Cost after iteration 254: 0.004440\n",
      "epoch:  255\n",
      "Cost after iteration 255: 0.021057\n",
      "epoch:  256\n",
      "Cost after iteration 256: 0.019543\n",
      "epoch:  257\n",
      "Cost after iteration 257: 0.007700\n",
      "epoch:  258\n",
      "Cost after iteration 258: 0.021993\n",
      "epoch:  259\n",
      "Cost after iteration 259: 0.002532\n",
      "epoch:  260\n",
      "Cost after iteration 260: 0.007866\n",
      "epoch:  261\n",
      "Cost after iteration 261: 0.006773\n",
      "epoch:  262\n",
      "Cost after iteration 262: 0.003627\n",
      "epoch:  263\n",
      "Cost after iteration 263: 0.007824\n",
      "epoch:  264\n",
      "Cost after iteration 264: 0.013895\n",
      "epoch:  265\n",
      "Cost after iteration 265: 0.012413\n",
      "epoch:  266\n",
      "Cost after iteration 266: 0.003006\n",
      "epoch:  267\n",
      "Cost after iteration 267: 0.025986\n",
      "epoch:  268\n",
      "Cost after iteration 268: 0.014797\n",
      "epoch:  269\n",
      "Cost after iteration 269: 0.013650\n",
      "epoch:  270\n",
      "Cost after iteration 270: 0.009000\n",
      "epoch:  271\n",
      "Cost after iteration 271: 0.005948\n",
      "epoch:  272\n",
      "Cost after iteration 272: 0.021995\n",
      "epoch:  273\n",
      "Cost after iteration 273: 0.002360\n",
      "epoch:  274\n",
      "Cost after iteration 274: 0.009093\n",
      "epoch:  275\n",
      "Cost after iteration 275: 0.019885\n",
      "epoch:  276\n",
      "Cost after iteration 276: 0.015387\n",
      "epoch:  277\n",
      "Cost after iteration 277: 0.003228\n",
      "epoch:  278\n",
      "Cost after iteration 278: 0.007188\n",
      "epoch:  279\n",
      "Cost after iteration 279: 0.005216\n",
      "epoch:  280\n",
      "Cost after iteration 280: 0.018526\n",
      "epoch:  281\n",
      "Cost after iteration 281: 0.009634\n",
      "epoch:  282\n",
      "Cost after iteration 282: 0.012908\n",
      "epoch:  283\n",
      "Cost after iteration 283: 0.012432\n",
      "epoch:  284\n",
      "Cost after iteration 284: 0.010481\n",
      "epoch:  285\n",
      "Cost after iteration 285: 0.016578\n",
      "epoch:  286\n",
      "Cost after iteration 286: 0.013201\n",
      "epoch:  287\n",
      "Cost after iteration 287: 0.013561\n",
      "epoch:  288\n",
      "Cost after iteration 288: 0.011690\n",
      "epoch:  289\n",
      "Cost after iteration 289: 0.018581\n",
      "epoch:  290\n",
      "Cost after iteration 290: 0.015427\n",
      "epoch:  291\n",
      "Cost after iteration 291: 0.018163\n",
      "epoch:  292\n",
      "Cost after iteration 292: 0.010639\n",
      "epoch:  293\n",
      "Cost after iteration 293: 0.015198\n",
      "epoch:  294\n",
      "Cost after iteration 294: 0.008138\n",
      "epoch:  295\n",
      "Cost after iteration 295: 0.005701\n",
      "epoch:  296\n",
      "Cost after iteration 296: 0.007453\n",
      "epoch:  297\n",
      "Cost after iteration 297: 0.020225\n",
      "epoch:  298\n",
      "Cost after iteration 298: 0.012065\n",
      "epoch:  299\n",
      "Cost after iteration 299: 0.010032\n",
      "epoch:  300\n",
      "Cost after iteration 300: 0.012636\n",
      "epoch:  301\n",
      "Cost after iteration 301: 0.013355\n",
      "epoch:  302\n",
      "Cost after iteration 302: 0.009205\n",
      "epoch:  303\n",
      "Cost after iteration 303: 0.007640\n",
      "epoch:  304\n",
      "Cost after iteration 304: 0.009949\n",
      "epoch:  305\n",
      "Cost after iteration 305: 0.009398\n",
      "epoch:  306\n",
      "Cost after iteration 306: 0.008330\n",
      "epoch:  307\n",
      "Cost after iteration 307: 0.021213\n",
      "epoch:  308\n",
      "Cost after iteration 308: 0.022190\n",
      "epoch:  309\n",
      "Cost after iteration 309: 0.021009\n",
      "epoch:  310\n",
      "Cost after iteration 310: 0.008507\n",
      "epoch:  311\n",
      "Cost after iteration 311: 0.017831\n",
      "epoch:  312\n",
      "Cost after iteration 312: 0.018500\n",
      "epoch:  313\n",
      "Cost after iteration 313: 0.023242\n",
      "epoch:  314\n",
      "Cost after iteration 314: 0.004355\n",
      "epoch:  315\n",
      "Cost after iteration 315: 0.013012\n",
      "epoch:  316\n",
      "Cost after iteration 316: 0.013873\n",
      "epoch:  317\n",
      "Cost after iteration 317: 0.019107\n",
      "epoch:  318\n",
      "Cost after iteration 318: 0.010108\n",
      "epoch:  319\n",
      "Cost after iteration 319: 0.017301\n",
      "epoch:  320\n",
      "Cost after iteration 320: 0.006356\n",
      "epoch:  321\n",
      "Cost after iteration 321: 0.004287\n",
      "epoch:  322\n",
      "Cost after iteration 322: 0.015325\n",
      "epoch:  323\n",
      "Cost after iteration 323: 0.010546\n",
      "epoch:  324\n",
      "Cost after iteration 324: 0.019270\n",
      "epoch:  325\n",
      "Cost after iteration 325: 0.015334\n",
      "epoch:  326\n",
      "Cost after iteration 326: 0.011776\n",
      "epoch:  327\n",
      "Cost after iteration 327: 0.008078\n",
      "epoch:  328\n",
      "Cost after iteration 328: 0.009438\n",
      "epoch:  329\n",
      "Cost after iteration 329: 0.011121\n",
      "epoch:  330\n",
      "Cost after iteration 330: 0.025359\n",
      "epoch:  331\n",
      "Cost after iteration 331: 0.005700\n",
      "epoch:  332\n",
      "Cost after iteration 332: 0.003252\n",
      "epoch:  333\n",
      "Cost after iteration 333: 0.013201\n",
      "epoch:  334\n",
      "Cost after iteration 334: 0.006801\n",
      "epoch:  335\n",
      "Cost after iteration 335: 0.014304\n",
      "epoch:  336\n",
      "Cost after iteration 336: 0.005222\n",
      "epoch:  337\n",
      "Cost after iteration 337: 0.020521\n",
      "epoch:  338\n",
      "Cost after iteration 338: 0.018333\n",
      "epoch:  339\n",
      "Cost after iteration 339: 0.010005\n",
      "epoch:  340\n",
      "Cost after iteration 340: 0.020602\n",
      "epoch:  341\n",
      "Cost after iteration 341: 0.002027\n",
      "epoch:  342\n",
      "Cost after iteration 342: 0.004791\n",
      "epoch:  343\n",
      "Cost after iteration 343: 0.024401\n",
      "epoch:  344\n",
      "Cost after iteration 344: 0.012159\n",
      "epoch:  345\n",
      "Cost after iteration 345: 0.006866\n",
      "epoch:  346\n",
      "Cost after iteration 346: 0.011965\n",
      "epoch:  347\n",
      "Cost after iteration 347: 0.007117\n",
      "epoch:  348\n",
      "Cost after iteration 348: 0.004469\n",
      "epoch:  349\n",
      "Cost after iteration 349: 0.017858\n",
      "epoch:  350\n",
      "Cost after iteration 350: 0.011869\n",
      "epoch:  351\n",
      "Cost after iteration 351: 0.006106\n",
      "epoch:  352\n",
      "Cost after iteration 352: 0.017032\n",
      "epoch:  353\n",
      "Cost after iteration 353: 0.018898\n",
      "epoch:  354\n",
      "Cost after iteration 354: 0.009525\n",
      "epoch:  355\n",
      "Cost after iteration 355: 0.007439\n",
      "epoch:  356\n",
      "Cost after iteration 356: 0.011724\n",
      "epoch:  357\n",
      "Cost after iteration 357: 0.011723\n",
      "epoch:  358\n",
      "Cost after iteration 358: 0.005423\n",
      "epoch:  359\n",
      "Cost after iteration 359: 0.012811\n",
      "epoch:  360\n",
      "Cost after iteration 360: 0.005983\n",
      "epoch:  361\n",
      "Cost after iteration 361: 0.015942\n",
      "epoch:  362\n",
      "Cost after iteration 362: 0.017101\n",
      "epoch:  363\n",
      "Cost after iteration 363: 0.012804\n",
      "epoch:  364\n",
      "Cost after iteration 364: 0.002145\n",
      "epoch:  365\n",
      "Cost after iteration 365: 0.002454\n",
      "epoch:  366\n",
      "Cost after iteration 366: 0.016908\n",
      "epoch:  367\n",
      "Cost after iteration 367: 0.000847\n",
      "epoch:  368\n",
      "Cost after iteration 368: 0.001919\n",
      "epoch:  369\n",
      "Cost after iteration 369: 0.014456\n",
      "epoch:  370\n",
      "Cost after iteration 370: 0.012732\n",
      "epoch:  371\n",
      "Cost after iteration 371: 0.003123\n",
      "epoch:  372\n",
      "Cost after iteration 372: 0.014256\n",
      "epoch:  373\n",
      "Cost after iteration 373: 0.004904\n",
      "epoch:  374\n",
      "Cost after iteration 374: 0.014394\n",
      "epoch:  375\n",
      "Cost after iteration 375: 0.012294\n",
      "epoch:  376\n",
      "Cost after iteration 376: 0.014550\n",
      "epoch:  377\n",
      "Cost after iteration 377: 0.016696\n",
      "epoch:  378\n",
      "Cost after iteration 378: 0.002673\n",
      "epoch:  379\n",
      "Cost after iteration 379: 0.013987\n",
      "epoch:  380\n",
      "Cost after iteration 380: 0.007551\n",
      "epoch:  381\n",
      "Cost after iteration 381: 0.004792\n",
      "epoch:  382\n",
      "Cost after iteration 382: 0.022199\n",
      "epoch:  383\n",
      "Cost after iteration 383: 0.012238\n",
      "epoch:  384\n",
      "Cost after iteration 384: 0.008722\n",
      "epoch:  385\n",
      "Cost after iteration 385: 0.004340\n",
      "epoch:  386\n",
      "Cost after iteration 386: 0.014635\n",
      "epoch:  387\n",
      "Cost after iteration 387: 0.008940\n",
      "epoch:  388\n",
      "Cost after iteration 388: 0.006801\n",
      "epoch:  389\n",
      "Cost after iteration 389: 0.013453\n",
      "epoch:  390\n",
      "Cost after iteration 390: 0.012498\n",
      "epoch:  391\n",
      "Cost after iteration 391: 0.018015\n",
      "epoch:  392\n",
      "Cost after iteration 392: 0.004588\n",
      "epoch:  393\n",
      "Cost after iteration 393: 0.007054\n",
      "epoch:  394\n",
      "Cost after iteration 394: 0.007010\n",
      "epoch:  395\n",
      "Cost after iteration 395: 0.002693\n",
      "epoch:  396\n",
      "Cost after iteration 396: 0.001767\n",
      "epoch:  397\n",
      "Cost after iteration 397: 0.016725\n",
      "epoch:  398\n",
      "Cost after iteration 398: 0.004512\n",
      "epoch:  399\n",
      "Cost after iteration 399: 0.012699\n",
      "epoch:  400\n",
      "Cost after iteration 400: 0.007635\n",
      "epoch:  401\n",
      "Cost after iteration 401: 0.014424\n",
      "epoch:  402\n",
      "Cost after iteration 402: 0.007813\n",
      "epoch:  403\n",
      "Cost after iteration 403: 0.008805\n",
      "epoch:  404\n",
      "Cost after iteration 404: 0.008459\n",
      "epoch:  405\n",
      "Cost after iteration 405: 0.012036\n",
      "epoch:  406\n",
      "Cost after iteration 406: 0.021608\n",
      "epoch:  407\n",
      "Cost after iteration 407: 0.007755\n",
      "epoch:  408\n",
      "Cost after iteration 408: 0.002131\n",
      "epoch:  409\n",
      "Cost after iteration 409: 0.006732\n",
      "epoch:  410\n",
      "Cost after iteration 410: 0.021590\n",
      "epoch:  411\n",
      "Cost after iteration 411: 0.002760\n",
      "epoch:  412\n",
      "Cost after iteration 412: 0.008236\n",
      "epoch:  413\n",
      "Cost after iteration 413: 0.010714\n",
      "epoch:  414\n",
      "Cost after iteration 414: 0.005322\n",
      "epoch:  415\n",
      "Cost after iteration 415: 0.003907\n",
      "epoch:  416\n",
      "Cost after iteration 416: 0.017464\n",
      "epoch:  417\n",
      "Cost after iteration 417: 0.014815\n",
      "epoch:  418\n",
      "Cost after iteration 418: 0.013720\n",
      "epoch:  419\n",
      "Cost after iteration 419: 0.014189\n",
      "epoch:  420\n",
      "Cost after iteration 420: 0.026870\n",
      "epoch:  421\n",
      "Cost after iteration 421: 0.007646\n",
      "epoch:  422\n",
      "Cost after iteration 422: 0.008735\n",
      "epoch:  423\n",
      "Cost after iteration 423: 0.003979\n",
      "epoch:  424\n",
      "Cost after iteration 424: 0.008763\n",
      "epoch:  425\n",
      "Cost after iteration 425: 0.014812\n",
      "epoch:  426\n",
      "Cost after iteration 426: 0.006510\n",
      "epoch:  427\n",
      "Cost after iteration 427: 0.013905\n",
      "epoch:  428\n",
      "Cost after iteration 428: 0.009626\n",
      "epoch:  429\n",
      "Cost after iteration 429: 0.006824\n",
      "epoch:  430\n",
      "Cost after iteration 430: 0.011715\n",
      "epoch:  431\n",
      "Cost after iteration 431: 0.009719\n",
      "epoch:  432\n",
      "Cost after iteration 432: 0.004055\n",
      "epoch:  433\n",
      "Cost after iteration 433: 0.025374\n",
      "epoch:  434\n",
      "Cost after iteration 434: 0.005223\n",
      "epoch:  435\n",
      "Cost after iteration 435: 0.009175\n",
      "epoch:  436\n",
      "Cost after iteration 436: 0.005321\n",
      "epoch:  437\n",
      "Cost after iteration 437: 0.003522\n",
      "epoch:  438\n",
      "Cost after iteration 438: 0.013663\n",
      "epoch:  439\n",
      "Cost after iteration 439: 0.019701\n",
      "epoch:  440\n",
      "Cost after iteration 440: 0.004294\n",
      "epoch:  441\n",
      "Cost after iteration 441: 0.029727\n",
      "epoch:  442\n",
      "Cost after iteration 442: 0.002923\n",
      "epoch:  443\n",
      "Cost after iteration 443: 0.020829\n",
      "epoch:  444\n",
      "Cost after iteration 444: 0.009478\n",
      "epoch:  445\n",
      "Cost after iteration 445: 0.018199\n",
      "epoch:  446\n",
      "Cost after iteration 446: 0.019504\n",
      "epoch:  447\n",
      "Cost after iteration 447: 0.002430\n",
      "epoch:  448\n",
      "Cost after iteration 448: 0.006378\n",
      "epoch:  449\n",
      "Cost after iteration 449: 0.005130\n",
      "epoch:  450\n",
      "Cost after iteration 450: 0.010230\n",
      "epoch:  451\n",
      "Cost after iteration 451: 0.005386\n",
      "epoch:  452\n",
      "Cost after iteration 452: 0.012114\n",
      "epoch:  453\n",
      "Cost after iteration 453: 0.010345\n",
      "epoch:  454\n",
      "Cost after iteration 454: 0.004330\n",
      "epoch:  455\n",
      "Cost after iteration 455: 0.001620\n",
      "epoch:  456\n",
      "Cost after iteration 456: 0.010407\n",
      "epoch:  457\n",
      "Cost after iteration 457: 0.004115\n",
      "epoch:  458\n",
      "Cost after iteration 458: 0.006814\n",
      "epoch:  459\n",
      "Cost after iteration 459: 0.017009\n",
      "epoch:  460\n",
      "Cost after iteration 460: 0.004181\n",
      "epoch:  461\n",
      "Cost after iteration 461: 0.004839\n",
      "epoch:  462\n",
      "Cost after iteration 462: 0.008962\n",
      "epoch:  463\n",
      "Cost after iteration 463: 0.011158\n",
      "epoch:  464\n",
      "Cost after iteration 464: 0.010766\n",
      "epoch:  465\n",
      "Cost after iteration 465: 0.009047\n",
      "epoch:  466\n",
      "Cost after iteration 466: 0.007592\n",
      "epoch:  467\n",
      "Cost after iteration 467: 0.005498\n",
      "epoch:  468\n",
      "Cost after iteration 468: 0.003757\n",
      "epoch:  469\n",
      "Cost after iteration 469: 0.011797\n",
      "epoch:  470\n",
      "Cost after iteration 470: 0.004388\n",
      "epoch:  471\n",
      "Cost after iteration 471: 0.013673\n",
      "epoch:  472\n",
      "Cost after iteration 472: 0.022129\n",
      "epoch:  473\n",
      "Cost after iteration 473: 0.017562\n",
      "epoch:  474\n",
      "Cost after iteration 474: 0.003995\n",
      "epoch:  475\n",
      "Cost after iteration 475: 0.008856\n",
      "epoch:  476\n",
      "Cost after iteration 476: 0.015757\n",
      "epoch:  477\n",
      "Cost after iteration 477: 0.013152\n",
      "epoch:  478\n",
      "Cost after iteration 478: 0.003857\n",
      "epoch:  479\n",
      "Cost after iteration 479: 0.014303\n",
      "epoch:  480\n",
      "Cost after iteration 480: 0.009203\n",
      "epoch:  481\n",
      "Cost after iteration 481: 0.002218\n",
      "epoch:  482\n",
      "Cost after iteration 482: 0.015877\n",
      "epoch:  483\n",
      "Cost after iteration 483: 0.011018\n",
      "epoch:  484\n",
      "Cost after iteration 484: 0.002362\n",
      "epoch:  485\n",
      "Cost after iteration 485: 0.015983\n",
      "epoch:  486\n",
      "Cost after iteration 486: 0.018469\n",
      "epoch:  487\n",
      "Cost after iteration 487: 0.008318\n",
      "epoch:  488\n",
      "Cost after iteration 488: 0.004703\n",
      "epoch:  489\n",
      "Cost after iteration 489: 0.013555\n",
      "epoch:  490\n",
      "Cost after iteration 490: 0.006693\n",
      "epoch:  491\n",
      "Cost after iteration 491: 0.010328\n",
      "epoch:  492\n",
      "Cost after iteration 492: 0.017354\n",
      "epoch:  493\n",
      "Cost after iteration 493: 0.005931\n",
      "epoch:  494\n",
      "Cost after iteration 494: 0.003346\n",
      "epoch:  495\n",
      "Cost after iteration 495: 0.010315\n",
      "epoch:  496\n",
      "Cost after iteration 496: 0.013896\n",
      "epoch:  497\n",
      "Cost after iteration 497: 0.012692\n",
      "epoch:  498\n",
      "Cost after iteration 498: 0.005188\n",
      "epoch:  499\n",
      "Cost after iteration 499: 0.009450\n",
      "epoch:  500\n",
      "Cost after iteration 500: 0.006789\n",
      "epoch:  501\n",
      "Cost after iteration 501: 0.016556\n",
      "epoch:  502\n",
      "Cost after iteration 502: 0.019876\n",
      "epoch:  503\n",
      "Cost after iteration 503: 0.001806\n",
      "epoch:  504\n",
      "Cost after iteration 504: 0.008710\n",
      "epoch:  505\n",
      "Cost after iteration 505: 0.007602\n",
      "epoch:  506\n",
      "Cost after iteration 506: 0.013350\n",
      "epoch:  507\n",
      "Cost after iteration 507: 0.011966\n",
      "epoch:  508\n",
      "Cost after iteration 508: 0.016263\n",
      "epoch:  509\n",
      "Cost after iteration 509: 0.007700\n",
      "epoch:  510\n",
      "Cost after iteration 510: 0.006693\n",
      "epoch:  511\n",
      "Cost after iteration 511: 0.008185\n",
      "epoch:  512\n",
      "Cost after iteration 512: 0.009958\n",
      "epoch:  513\n",
      "Cost after iteration 513: 0.009962\n",
      "epoch:  514\n",
      "Cost after iteration 514: 0.005486\n",
      "epoch:  515\n",
      "Cost after iteration 515: 0.005282\n",
      "epoch:  516\n",
      "Cost after iteration 516: 0.010094\n",
      "epoch:  517\n",
      "Cost after iteration 517: 0.012041\n",
      "epoch:  518\n",
      "Cost after iteration 518: 0.003661\n",
      "epoch:  519\n",
      "Cost after iteration 519: 0.011218\n",
      "epoch:  520\n",
      "Cost after iteration 520: 0.008095\n",
      "epoch:  521\n",
      "Cost after iteration 521: 0.012733\n",
      "epoch:  522\n",
      "Cost after iteration 522: 0.008175\n",
      "epoch:  523\n",
      "Cost after iteration 523: 0.007617\n",
      "epoch:  524\n",
      "Cost after iteration 524: 0.010974\n",
      "epoch:  525\n",
      "Cost after iteration 525: 0.023715\n",
      "epoch:  526\n",
      "Cost after iteration 526: 0.008208\n",
      "epoch:  527\n",
      "Cost after iteration 527: 0.011096\n",
      "epoch:  528\n",
      "Cost after iteration 528: 0.005585\n",
      "epoch:  529\n",
      "Cost after iteration 529: 0.011888\n",
      "epoch:  530\n",
      "Cost after iteration 530: 0.003599\n",
      "epoch:  531\n",
      "Cost after iteration 531: 0.006735\n",
      "epoch:  532\n",
      "Cost after iteration 532: 0.010494\n",
      "epoch:  533\n",
      "Cost after iteration 533: 0.021603\n",
      "epoch:  534\n",
      "Cost after iteration 534: 0.011786\n",
      "epoch:  535\n",
      "Cost after iteration 535: 0.004511\n",
      "epoch:  536\n",
      "Cost after iteration 536: 0.011189\n",
      "epoch:  537\n",
      "Cost after iteration 537: 0.009774\n",
      "epoch:  538\n",
      "Cost after iteration 538: 0.026103\n",
      "epoch:  539\n",
      "Cost after iteration 539: 0.008321\n",
      "epoch:  540\n",
      "Cost after iteration 540: 0.004428\n",
      "epoch:  541\n",
      "Cost after iteration 541: 0.004752\n",
      "epoch:  542\n",
      "Cost after iteration 542: 0.018302\n",
      "epoch:  543\n",
      "Cost after iteration 543: 0.016550\n",
      "epoch:  544\n",
      "Cost after iteration 544: 0.005157\n",
      "epoch:  545\n",
      "Cost after iteration 545: 0.018105\n",
      "epoch:  546\n",
      "Cost after iteration 546: 0.015177\n",
      "epoch:  547\n",
      "Cost after iteration 547: 0.018662\n",
      "epoch:  548\n",
      "Cost after iteration 548: 0.004846\n",
      "epoch:  549\n",
      "Cost after iteration 549: 0.004733\n",
      "epoch:  550\n",
      "Cost after iteration 550: 0.004459\n",
      "epoch:  551\n",
      "Cost after iteration 551: 0.014117\n",
      "epoch:  552\n",
      "Cost after iteration 552: 0.006055\n",
      "epoch:  553\n",
      "Cost after iteration 553: 0.003827\n",
      "epoch:  554\n",
      "Cost after iteration 554: 0.012429\n",
      "epoch:  555\n",
      "Cost after iteration 555: 0.006261\n",
      "epoch:  556\n",
      "Cost after iteration 556: 0.010815\n",
      "epoch:  557\n",
      "Cost after iteration 557: 0.004193\n",
      "epoch:  558\n",
      "Cost after iteration 558: 0.019424\n",
      "epoch:  559\n",
      "Cost after iteration 559: 0.006185\n",
      "epoch:  560\n",
      "Cost after iteration 560: 0.009163\n",
      "epoch:  561\n",
      "Cost after iteration 561: 0.013157\n",
      "epoch:  562\n",
      "Cost after iteration 562: 0.008577\n",
      "epoch:  563\n",
      "Cost after iteration 563: 0.022084\n",
      "epoch:  564\n",
      "Cost after iteration 564: 0.025156\n",
      "epoch:  565\n",
      "Cost after iteration 565: 0.011741\n",
      "epoch:  566\n",
      "Cost after iteration 566: 0.010479\n",
      "epoch:  567\n",
      "Cost after iteration 567: 0.009544\n",
      "epoch:  568\n",
      "Cost after iteration 568: 0.007975\n",
      "epoch:  569\n",
      "Cost after iteration 569: 0.018735\n",
      "epoch:  570\n",
      "Cost after iteration 570: 0.016852\n",
      "epoch:  571\n",
      "Cost after iteration 571: 0.003668\n",
      "epoch:  572\n",
      "Cost after iteration 572: 0.006538\n",
      "epoch:  573\n",
      "Cost after iteration 573: 0.011519\n",
      "epoch:  574\n",
      "Cost after iteration 574: 0.004158\n",
      "epoch:  575\n",
      "Cost after iteration 575: 0.008565\n",
      "epoch:  576\n",
      "Cost after iteration 576: 0.012726\n",
      "epoch:  577\n",
      "Cost after iteration 577: 0.004616\n",
      "epoch:  578\n",
      "Cost after iteration 578: 0.013916\n",
      "epoch:  579\n",
      "Cost after iteration 579: 0.002830\n",
      "epoch:  580\n",
      "Cost after iteration 580: 0.009959\n",
      "epoch:  581\n",
      "Cost after iteration 581: 0.019121\n",
      "epoch:  582\n",
      "Cost after iteration 582: 0.012580\n",
      "epoch:  583\n",
      "Cost after iteration 583: 0.010427\n",
      "epoch:  584\n",
      "Cost after iteration 584: 0.014638\n",
      "epoch:  585\n",
      "Cost after iteration 585: 0.012234\n",
      "epoch:  586\n",
      "Cost after iteration 586: 0.006908\n",
      "epoch:  587\n",
      "Cost after iteration 587: 0.005670\n",
      "epoch:  588\n",
      "Cost after iteration 588: 0.001454\n",
      "epoch:  589\n",
      "Cost after iteration 589: 0.007858\n",
      "epoch:  590\n",
      "Cost after iteration 590: 0.005851\n",
      "epoch:  591\n",
      "Cost after iteration 591: 0.010054\n",
      "epoch:  592\n",
      "Cost after iteration 592: 0.009137\n",
      "epoch:  593\n",
      "Cost after iteration 593: 0.016101\n",
      "epoch:  594\n",
      "Cost after iteration 594: 0.009599\n",
      "epoch:  595\n",
      "Cost after iteration 595: 0.004870\n",
      "epoch:  596\n",
      "Cost after iteration 596: 0.008704\n",
      "epoch:  597\n",
      "Cost after iteration 597: 0.009877\n",
      "epoch:  598\n",
      "Cost after iteration 598: 0.008428\n",
      "epoch:  599\n",
      "Cost after iteration 599: 0.015657\n",
      "epoch:  600\n",
      "Cost after iteration 600: 0.006883\n",
      "epoch:  601\n",
      "Cost after iteration 601: 0.020462\n",
      "epoch:  602\n",
      "Cost after iteration 602: 0.009152\n",
      "epoch:  603\n",
      "Cost after iteration 603: 0.001541\n",
      "epoch:  604\n",
      "Cost after iteration 604: 0.010147\n",
      "epoch:  605\n",
      "Cost after iteration 605: 0.008960\n",
      "epoch:  606\n",
      "Cost after iteration 606: 0.004973\n",
      "epoch:  607\n",
      "Cost after iteration 607: 0.016556\n",
      "epoch:  608\n",
      "Cost after iteration 608: 0.002901\n",
      "epoch:  609\n",
      "Cost after iteration 609: 0.012997\n",
      "epoch:  610\n",
      "Cost after iteration 610: 0.003581\n",
      "epoch:  611\n",
      "Cost after iteration 611: 0.010618\n",
      "epoch:  612\n",
      "Cost after iteration 612: 0.003511\n",
      "epoch:  613\n",
      "Cost after iteration 613: 0.013693\n",
      "epoch:  614\n",
      "Cost after iteration 614: 0.013594\n",
      "epoch:  615\n",
      "Cost after iteration 615: 0.025332\n",
      "epoch:  616\n",
      "Cost after iteration 616: 0.013012\n",
      "epoch:  617\n",
      "Cost after iteration 617: 0.011539\n",
      "epoch:  618\n",
      "Cost after iteration 618: 0.015366\n",
      "epoch:  619\n",
      "Cost after iteration 619: 0.021792\n",
      "epoch:  620\n",
      "Cost after iteration 620: 0.023692\n",
      "epoch:  621\n",
      "Cost after iteration 621: 0.009600\n",
      "epoch:  622\n",
      "Cost after iteration 622: 0.018272\n",
      "epoch:  623\n",
      "Cost after iteration 623: 0.011676\n",
      "epoch:  624\n",
      "Cost after iteration 624: 0.007977\n",
      "epoch:  625\n",
      "Cost after iteration 625: 0.008285\n",
      "epoch:  626\n",
      "Cost after iteration 626: 0.019454\n",
      "epoch:  627\n",
      "Cost after iteration 627: 0.019440\n",
      "epoch:  628\n",
      "Cost after iteration 628: 0.002977\n",
      "epoch:  629\n",
      "Cost after iteration 629: 0.017396\n",
      "epoch:  630\n",
      "Cost after iteration 630: 0.013151\n",
      "epoch:  631\n",
      "Cost after iteration 631: 0.008325\n",
      "epoch:  632\n",
      "Cost after iteration 632: 0.007572\n",
      "epoch:  633\n",
      "Cost after iteration 633: 0.010549\n",
      "epoch:  634\n",
      "Cost after iteration 634: 0.014269\n",
      "epoch:  635\n",
      "Cost after iteration 635: 0.008227\n",
      "epoch:  636\n",
      "Cost after iteration 636: 0.003889\n",
      "epoch:  637\n",
      "Cost after iteration 637: 0.007931\n",
      "epoch:  638\n",
      "Cost after iteration 638: 0.001466\n",
      "epoch:  639\n",
      "Cost after iteration 639: 0.009000\n",
      "epoch:  640\n",
      "Cost after iteration 640: 0.001431\n",
      "epoch:  641\n",
      "Cost after iteration 641: 0.000849\n",
      "epoch:  642\n",
      "Cost after iteration 642: 0.007818\n",
      "epoch:  643\n",
      "Cost after iteration 643: 0.011584\n",
      "epoch:  644\n",
      "Cost after iteration 644: 0.018763\n",
      "epoch:  645\n",
      "Cost after iteration 645: 0.018168\n",
      "epoch:  646\n",
      "Cost after iteration 646: 0.012680\n",
      "epoch:  647\n",
      "Cost after iteration 647: 0.007764\n",
      "epoch:  648\n",
      "Cost after iteration 648: 0.008469\n",
      "epoch:  649\n",
      "Cost after iteration 649: 0.005356\n",
      "epoch:  650\n",
      "Cost after iteration 650: 0.007134\n",
      "epoch:  651\n",
      "Cost after iteration 651: 0.008636\n",
      "epoch:  652\n",
      "Cost after iteration 652: 0.005407\n",
      "epoch:  653\n",
      "Cost after iteration 653: 0.009130\n",
      "epoch:  654\n",
      "Cost after iteration 654: 0.001158\n",
      "epoch:  655\n",
      "Cost after iteration 655: 0.004618\n",
      "epoch:  656\n",
      "Cost after iteration 656: 0.014586\n",
      "epoch:  657\n",
      "Cost after iteration 657: 0.013909\n",
      "epoch:  658\n",
      "Cost after iteration 658: 0.010725\n",
      "epoch:  659\n",
      "Cost after iteration 659: 0.003896\n",
      "epoch:  660\n",
      "Cost after iteration 660: 0.013002\n",
      "epoch:  661\n",
      "Cost after iteration 661: 0.009474\n",
      "epoch:  662\n",
      "Cost after iteration 662: 0.021655\n",
      "epoch:  663\n",
      "Cost after iteration 663: 0.005130\n",
      "epoch:  664\n",
      "Cost after iteration 664: 0.006000\n",
      "epoch:  665\n",
      "Cost after iteration 665: 0.003010\n",
      "epoch:  666\n",
      "Cost after iteration 666: 0.006582\n",
      "epoch:  667\n",
      "Cost after iteration 667: 0.005136\n",
      "epoch:  668\n",
      "Cost after iteration 668: 0.001346\n",
      "epoch:  669\n",
      "Cost after iteration 669: 0.003821\n",
      "epoch:  670\n",
      "Cost after iteration 670: 0.003783\n",
      "epoch:  671\n",
      "Cost after iteration 671: 0.004272\n",
      "epoch:  672\n",
      "Cost after iteration 672: 0.012239\n",
      "epoch:  673\n",
      "Cost after iteration 673: 0.012795\n",
      "epoch:  674\n",
      "Cost after iteration 674: 0.006961\n",
      "epoch:  675\n",
      "Cost after iteration 675: 0.006805\n",
      "epoch:  676\n",
      "Cost after iteration 676: 0.007279\n",
      "epoch:  677\n",
      "Cost after iteration 677: 0.003955\n",
      "epoch:  678\n",
      "Cost after iteration 678: 0.006933\n",
      "epoch:  679\n",
      "Cost after iteration 679: 0.009609\n",
      "epoch:  680\n",
      "Cost after iteration 680: 0.007135\n",
      "epoch:  681\n",
      "Cost after iteration 681: 0.003071\n",
      "epoch:  682\n",
      "Cost after iteration 682: 0.010050\n",
      "epoch:  683\n",
      "Cost after iteration 683: 0.021490\n",
      "epoch:  684\n",
      "Cost after iteration 684: 0.012835\n",
      "epoch:  685\n",
      "Cost after iteration 685: 0.004400\n",
      "epoch:  686\n",
      "Cost after iteration 686: 0.005138\n",
      "epoch:  687\n",
      "Cost after iteration 687: 0.003451\n",
      "epoch:  688\n",
      "Cost after iteration 688: 0.013847\n",
      "epoch:  689\n",
      "Cost after iteration 689: 0.019353\n",
      "epoch:  690\n",
      "Cost after iteration 690: 0.010609\n",
      "epoch:  691\n",
      "Cost after iteration 691: 0.015898\n",
      "epoch:  692\n",
      "Cost after iteration 692: 0.003101\n",
      "epoch:  693\n",
      "Cost after iteration 693: 0.012298\n",
      "epoch:  694\n",
      "Cost after iteration 694: 0.004350\n",
      "epoch:  695\n",
      "Cost after iteration 695: 0.017643\n",
      "epoch:  696\n",
      "Cost after iteration 696: 0.012970\n",
      "epoch:  697\n",
      "Cost after iteration 697: 0.019819\n",
      "epoch:  698\n",
      "Cost after iteration 698: 0.001693\n",
      "epoch:  699\n",
      "Cost after iteration 699: 0.013279\n",
      "epoch:  700\n",
      "Cost after iteration 700: 0.003843\n",
      "epoch:  701\n",
      "Cost after iteration 701: 0.016179\n",
      "epoch:  702\n",
      "Cost after iteration 702: 0.017220\n",
      "epoch:  703\n",
      "Cost after iteration 703: 0.011805\n",
      "epoch:  704\n",
      "Cost after iteration 704: 0.008790\n",
      "epoch:  705\n",
      "Cost after iteration 705: 0.005140\n",
      "epoch:  706\n",
      "Cost after iteration 706: 0.013019\n",
      "epoch:  707\n",
      "Cost after iteration 707: 0.017289\n",
      "epoch:  708\n",
      "Cost after iteration 708: 0.006250\n",
      "epoch:  709\n",
      "Cost after iteration 709: 0.009920\n",
      "epoch:  710\n",
      "Cost after iteration 710: 0.008251\n",
      "epoch:  711\n",
      "Cost after iteration 711: 0.003647\n",
      "epoch:  712\n",
      "Cost after iteration 712: 0.016088\n",
      "epoch:  713\n",
      "Cost after iteration 713: 0.006666\n",
      "epoch:  714\n",
      "Cost after iteration 714: 0.013103\n",
      "epoch:  715\n",
      "Cost after iteration 715: 0.001339\n",
      "epoch:  716\n",
      "Cost after iteration 716: 0.006523\n",
      "epoch:  717\n",
      "Cost after iteration 717: 0.003010\n",
      "epoch:  718\n",
      "Cost after iteration 718: 0.014380\n",
      "epoch:  719\n",
      "Cost after iteration 719: 0.012247\n",
      "epoch:  720\n",
      "Cost after iteration 720: 0.008658\n",
      "epoch:  721\n",
      "Cost after iteration 721: 0.005894\n",
      "epoch:  722\n",
      "Cost after iteration 722: 0.015854\n",
      "epoch:  723\n",
      "Cost after iteration 723: 0.007437\n",
      "epoch:  724\n",
      "Cost after iteration 724: 0.007779\n",
      "epoch:  725\n",
      "Cost after iteration 725: 0.007011\n",
      "epoch:  726\n",
      "Cost after iteration 726: 0.003874\n",
      "epoch:  727\n",
      "Cost after iteration 727: 0.007835\n",
      "epoch:  728\n",
      "Cost after iteration 728: 0.013299\n",
      "epoch:  729\n",
      "Cost after iteration 729: 0.003254\n",
      "epoch:  730\n",
      "Cost after iteration 730: 0.012137\n",
      "epoch:  731\n",
      "Cost after iteration 731: 0.007838\n",
      "epoch:  732\n",
      "Cost after iteration 732: 0.007428\n",
      "epoch:  733\n",
      "Cost after iteration 733: 0.009918\n",
      "epoch:  734\n",
      "Cost after iteration 734: 0.007710\n",
      "epoch:  735\n",
      "Cost after iteration 735: 0.014009\n",
      "epoch:  736\n",
      "Cost after iteration 736: 0.017207\n",
      "epoch:  737\n",
      "Cost after iteration 737: 0.003865\n",
      "epoch:  738\n",
      "Cost after iteration 738: 0.007358\n",
      "epoch:  739\n",
      "Cost after iteration 739: 0.010649\n",
      "epoch:  740\n",
      "Cost after iteration 740: 0.005435\n",
      "epoch:  741\n",
      "Cost after iteration 741: 0.017039\n",
      "epoch:  742\n",
      "Cost after iteration 742: 0.003814\n",
      "epoch:  743\n",
      "Cost after iteration 743: 0.008084\n",
      "epoch:  744\n",
      "Cost after iteration 744: 0.002585\n",
      "epoch:  745\n",
      "Cost after iteration 745: 0.004894\n",
      "epoch:  746\n",
      "Cost after iteration 746: 0.003155\n",
      "epoch:  747\n",
      "Cost after iteration 747: 0.008570\n",
      "epoch:  748\n",
      "Cost after iteration 748: 0.011465\n",
      "epoch:  749\n",
      "Cost after iteration 749: 0.016314\n",
      "epoch:  750\n",
      "Cost after iteration 750: 0.014560\n",
      "epoch:  751\n",
      "Cost after iteration 751: 0.009151\n",
      "epoch:  752\n",
      "Cost after iteration 752: 0.009838\n",
      "epoch:  753\n",
      "Cost after iteration 753: 0.009853\n",
      "epoch:  754\n",
      "Cost after iteration 754: 0.003770\n",
      "epoch:  755\n",
      "Cost after iteration 755: 0.012449\n",
      "epoch:  756\n",
      "Cost after iteration 756: 0.015139\n",
      "epoch:  757\n",
      "Cost after iteration 757: 0.003031\n",
      "epoch:  758\n",
      "Cost after iteration 758: 0.006924\n",
      "epoch:  759\n",
      "Cost after iteration 759: 0.021124\n",
      "epoch:  760\n",
      "Cost after iteration 760: 0.005190\n",
      "epoch:  761\n",
      "Cost after iteration 761: 0.005331\n",
      "epoch:  762\n",
      "Cost after iteration 762: 0.008658\n",
      "epoch:  763\n",
      "Cost after iteration 763: 0.002971\n",
      "epoch:  764\n",
      "Cost after iteration 764: 0.008687\n",
      "epoch:  765\n",
      "Cost after iteration 765: 0.014913\n",
      "epoch:  766\n",
      "Cost after iteration 766: 0.012223\n",
      "epoch:  767\n",
      "Cost after iteration 767: 0.014548\n",
      "epoch:  768\n",
      "Cost after iteration 768: 0.005522\n",
      "epoch:  769\n",
      "Cost after iteration 769: 0.011312\n",
      "epoch:  770\n",
      "Cost after iteration 770: 0.006225\n",
      "epoch:  771\n",
      "Cost after iteration 771: 0.005606\n",
      "epoch:  772\n",
      "Cost after iteration 772: 0.027805\n",
      "epoch:  773\n",
      "Cost after iteration 773: 0.017847\n",
      "epoch:  774\n",
      "Cost after iteration 774: 0.002248\n",
      "epoch:  775\n",
      "Cost after iteration 775: 0.011315\n",
      "epoch:  776\n",
      "Cost after iteration 776: 0.012123\n",
      "epoch:  777\n",
      "Cost after iteration 777: 0.007580\n",
      "epoch:  778\n",
      "Cost after iteration 778: 0.003962\n",
      "epoch:  779\n",
      "Cost after iteration 779: 0.018064\n",
      "epoch:  780\n",
      "Cost after iteration 780: 0.006533\n",
      "epoch:  781\n",
      "Cost after iteration 781: 0.007114\n",
      "epoch:  782\n",
      "Cost after iteration 782: 0.002782\n",
      "epoch:  783\n",
      "Cost after iteration 783: 0.005752\n",
      "epoch:  784\n",
      "Cost after iteration 784: 0.005911\n",
      "epoch:  785\n",
      "Cost after iteration 785: 0.007252\n",
      "epoch:  786\n",
      "Cost after iteration 786: 0.010226\n",
      "epoch:  787\n",
      "Cost after iteration 787: 0.024203\n",
      "epoch:  788\n",
      "Cost after iteration 788: 0.009822\n",
      "epoch:  789\n",
      "Cost after iteration 789: 0.009871\n",
      "epoch:  790\n",
      "Cost after iteration 790: 0.015431\n",
      "epoch:  791\n",
      "Cost after iteration 791: 0.008001\n",
      "epoch:  792\n",
      "Cost after iteration 792: 0.009466\n",
      "epoch:  793\n",
      "Cost after iteration 793: 0.013366\n",
      "epoch:  794\n",
      "Cost after iteration 794: 0.008095\n",
      "epoch:  795\n",
      "Cost after iteration 795: 0.013005\n",
      "epoch:  796\n",
      "Cost after iteration 796: 0.009665\n",
      "epoch:  797\n",
      "Cost after iteration 797: 0.016255\n",
      "epoch:  798\n",
      "Cost after iteration 798: 0.009412\n",
      "epoch:  799\n",
      "Cost after iteration 799: 0.010012\n",
      "epoch:  800\n",
      "Cost after iteration 800: 0.010523\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "learning_rate = 0.1\n",
    "num_iterations = 800\n",
    "batch_size = 64\n",
    "costs = []   # keep track of cost\n",
    "\n",
    "\n",
    "# build the model\n",
    "model = Model()\n",
    "model.add(Conv(filter_size=3, input_channel=1, output_channel=8, pad=1, stride=1))\n",
    "model.add(Activation(\"relu\", \"cross_entropy\"))\n",
    "model.add(MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "model.add(Conv(filter_size=3, input_channel=8, output_channel=16, pad=1, stride=1))\n",
    "model.add(Activation(\"relu\", \"cross_entropy\"))\n",
    "model.add(MaxPool(pool_size=2, stride=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, 512))\n",
    "model.add(Activation(\"relu\", \"cross_entropy\"))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(512, 1))\n",
    "model.add(Activation(\"sigmoid\", \"cross_entropy\"))\n",
    "\n",
    "# Loop (gradient descent)\n",
    "for i in range(0, num_iterations):\n",
    "    print(\"epoch: \",i+1)\n",
    "    mini_batches = random_mini_batches(X_train, y_train, batch_size)\n",
    "\n",
    "    learning_rate = learning_rate * 0.9 if (i % 10 == 0 and i != 0) else learning_rate\n",
    "\n",
    "    for batch in mini_batches:\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        # forward\n",
    "        AL = model.forward(x_batch)\n",
    "\n",
    "        # compute cost\n",
    "        cost = compute_BCE_loss(AL, y_batch)\n",
    "\n",
    "        # backward\n",
    "        dA_prev = model.backward(AL, y_batch)\n",
    "\n",
    "        # update\n",
    "        model.update(learning_rate)\n",
    "\n",
    "    print (\"Cost after iteration %i: %f\" %(i+1, cost))\n",
    "    costs.append(cost)\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-MWR00BQo15"
   },
   "source": [
    "## 4.4 Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "wzGHGrASQo15"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training------\n",
      "Accuracy: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()\n",
    "\n",
    "print('training------')\n",
    "pred_train = predict(model, X_val, y_val)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrasoS0gQo15"
   },
   "source": [
    "## 4.5 Generate the prediction\n",
    "- Remember to submit this to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "wKcWJUu8Qo15"
   },
   "outputs": [],
   "source": [
    "pred_test = predict(model, X_test)\n",
    "df = pd.DataFrame({\n",
    "    'ID': range(len(X_test)),\n",
    "    'Label': pred_test.astype(int).flatten()\n",
    "})\n",
    "df.to_csv('Lab5_prediction.csv', index=False, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXGnS3HQeNUc"
   },
   "source": [
    "# 5. Generate Lab5_output.npy\n",
    "- Remember to submit this to eeclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "twMsmXbQeDL_"
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert(list(output.keys()) == ['zero_padding', 'conv_single_step', 'conv_forward_1', 'conv_forward_2', 'conv_forward_3','conv_backward_1', 'conv_backward_2', 'conv_backward_3', 'conv_update_1', 'conv_update_2', 'maxpool_forward', 'maxpool_backward', 'flatten_forward', 'flatten_backward', 'model_1', 'model_2', 'model_3', 'model_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "bCJ0XTO_zE8A"
   },
   "outputs": [],
   "source": [
    "np.save(\"Lab5_output.npy\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "wFBFUUEg1to-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_padding: <class 'numpy.ndarray'>\n",
      "conv_single_step: <class 'numpy.float64'>\n",
      "conv_forward_1: <class 'tuple'>\n",
      "conv_forward_2: <class 'numpy.float64'>\n",
      "conv_forward_3: <class 'numpy.ndarray'>\n",
      "conv_backward_1: <class 'tuple'>\n",
      "conv_backward_2: <class 'numpy.float64'>\n",
      "conv_backward_3: <class 'numpy.ndarray'>\n",
      "conv_update_1: <class 'numpy.ndarray'>\n",
      "conv_update_2: <class 'numpy.ndarray'>\n",
      "maxpool_forward: <class 'numpy.ndarray'>\n",
      "maxpool_backward: <class 'numpy.ndarray'>\n",
      "flatten_forward: <class 'numpy.ndarray'>\n",
      "flatten_backward: <class 'numpy.ndarray'>\n",
      "model_1: <class 'numpy.ndarray'>\n",
      "model_2: <class 'numpy.ndarray'>\n",
      "model_3: <class 'numpy.ndarray'>\n",
      "model_4: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "submit = np.load(\"Lab5_output.npy\", allow_pickle=True).item()\n",
    "for key, value in submit.items():\n",
    "    print(str(key) + \": \" + str(type(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBkBtZHxIh8Z"
   },
   "source": [
    "Expected output:<br>\n",
    "<small>\n",
    "zero_padding： <class 'numpy.ndarray'> <br>\n",
    "conv_single_step： <class 'numpy.float64'> <br>\n",
    "conv_forward_1： <class 'tuple'> <br>\n",
    "conv_forward_2： <class 'numpy.float64'> <br>\n",
    "conv_forward_3： <class 'numpy.ndarray'> <br>\n",
    "conv_backward_1： <class 'tuple'> <br>\n",
    "conv_backward_2： <class 'numpy.float64'> <br>\n",
    "conv_backward_3： <class 'numpy.ndarray'> <br>\n",
    "conv_update_1： <class 'numpy.ndarray'> <br>\n",
    "conv_update_2： <class 'numpy.ndarray'> <br>\n",
    "maxpool_forward： <class 'numpy.ndarray'> <br>\n",
    "maxpool_backward： <class 'numpy.ndarray'> <br>\n",
    "flatten_forward： <class 'numpy.ndarray'> <br>\n",
    "flatten_backward： <class 'numpy.ndarray'> <br>\n",
    "model_1： <class 'numpy.ndarray'> <br>\n",
    "model_2： <class 'numpy.ndarray'> <br>\n",
    "model_3： <class 'numpy.ndarray'> <br>\n",
    "model_4： <class 'numpy.ndarray'> <br>\n",
    "</small>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
